{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepL_FinalProject.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1VDRp2gxkgk"
      },
      "source": [
        "### **Toulouse School of Economics**\n",
        "#### **M2 Statistics & Econometrics**\n",
        "---\n",
        "\n",
        "### **Mathematics of Deep Learning Algorithms, Part 2**\n",
        "# **Final Project: *Performance Benchmarking of Different Information Retrieval Methods***\n",
        "\n",
        "### **Anh-Dung LE, Paul MELKI**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QL_0ZCqPxkgr"
      },
      "source": [
        "In this project, we aim at comparing the performance of different Information Retrieval techniques, mainly: **BM25** and **BERT-based search engine**. We work on a corpus formed of the latest dump of English Wikipedia, and restrict our work to only a small subset of this dump (mainly, articles whose title starts with the letter 'A'), and that is due to unavailability of enough computational resources. \n",
        "\n",
        "But first, we start with some preliminary steps: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnlAZckrxkgs"
      },
      "source": [
        "### **Preliminaries & Corpus Creation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJ9X7zzqygvA",
        "outputId": "9b1477b3-4648-4632-d24c-eb62e270764d"
      },
      "source": [
        "# Install required libraries\r\n",
        "!pip install rank-bm25"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting rank-bm25\n",
            "  Downloading https://files.pythonhosted.org/packages/16/5a/23ed3132063a0684ea66fb410260c71c4ffda3b99f8f1c021d1e245401b5/rank_bm25-0.2.1-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from rank-bm25) (1.19.4)\n",
            "Installing collected packages: rank-bm25\n",
            "Successfully installed rank-bm25-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIAgpAGhIPSc",
        "outputId": "97e689d6-08a6-4c20-c26f-01df30b23b69"
      },
      "source": [
        "pip install -q tf-models-official==2.3.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 849kB 5.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 37.6MB 1.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 42.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 358kB 41.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 9.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 174kB 48.9MB/s \n",
            "\u001b[?25h  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CioRA6p1yv2F",
        "outputId": "de7eb3de-9f20-4df2-9d56-a38ef69fd686"
      },
      "source": [
        "# Define the path to the project's directory\r\n",
        "PATH = '/content/drive/MyDrive/College Material/Master 2/Mathematics of Deep Learning Algorithms/Final Project'\r\n",
        "\r\n",
        "# Load drive\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRLmf8D_xkgs"
      },
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import pprint as pp\n",
        "import numpy as np\n",
        "import json\n",
        "import tensorflow as tf \n",
        "from gensim.corpora import WikiCorpus\n",
        "from rank_bm25 import BM25Okapi, BM25Plus\n",
        "\n",
        "from official.modeling import tf_utils\n",
        "from official import nlp\n",
        "from official.nlp import bert\n",
        "\n",
        "# Load the required submodules\n",
        "import official.nlp.optimization\n",
        "import official.nlp.bert.bert_models\n",
        "import official.nlp.bert.configs\n",
        "import official.nlp.bert.run_classifier\n",
        "import official.nlp.bert.tokenization\n",
        "import official.nlp.data.classifier_data_lib\n",
        "import official.nlp.modeling.losses\n",
        "import official.nlp.modeling.models\n",
        "import official.nlp.modeling.networks"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JL3Mu_iExkgt"
      },
      "source": [
        "In order to create our own local textual corpus based from Wikipedia, we make use of the class `WikiCorpus` implement in the `gensim.corpora` library. This class implements different functions that facilitate the handling and manipulation of Wikipedia dumps, which are usually downloaded as BZ2-compressed XML files.\n",
        "\n",
        "Based on this library, we create our own function to read and save the corpus locally, with each Wikipedia being saved in its own `.txt` file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBoh4qKjxkgt"
      },
      "source": [
        "# Define function to read and create corpus from downloaded dump\n",
        "def make_corpus(in_file, out_directory):\n",
        "    \"\"\"\n",
        "    Function that converts a Wikipedia .xml dump into a \n",
        "    corpus, saving each article in a separate .txt file.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    @param in_file: str, \n",
        "        A valid string specifying the path to the local *.xml.bz2 Wikipedia \n",
        "        dump file.\n",
        "    @param out_directory, str,\n",
        "        A valid string specifying the path to the directory in which we wish to\n",
        "        save the created .txt files.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Instantiate WikiCorpus object, based on the local dump file.\n",
        "    wiki = WikiCorpus(in_file)\n",
        "    print(\"Corpus is read!\")\n",
        "    \n",
        "    # Initialize counter of articles read.\n",
        "    i = 0\n",
        "    \n",
        "    print(\"Getting texts...\")\n",
        "    # For new article read, do...\n",
        "    for text in wiki.get_texts():\n",
        "        # Create and open new file for new article.\n",
        "        output_file = open(f'{out_directory}\\\\{str(i+1)}.txt', 'w')\n",
        "        # Extract the text of the read article.\n",
        "        article_text = bytes(' '.join(text), 'utf-8').decode('utf-8') + '\\n'\n",
        "        # Take only first 1000 words from each article, to keep sizes small.\n",
        "        first_n_words = ' '.join(article_text.split(' ')[0:1000])\n",
        "        # Write text to file & close the file.\n",
        "        output_file.write(first_n_words)\n",
        "        output_file.close()\n",
        "        # Update counter\n",
        "        i = i + 1\n",
        "        # If 1000 articles have been read, stop reading.\n",
        "        if (i % 1000 == 0):\n",
        "            print(f'Processed {str(i)} articles')\n",
        "            break\n",
        "\n",
        "    print('Processing Complete!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "HWHc4OzFxkgu",
        "outputId": "146fb6d2-bb01-4c8d-bd2d-a62712f2dfcb"
      },
      "source": [
        "# Initialize input and output paths\n",
        "in_path = \"C:\\\\Users\\\\Paul\\\\Documents\\\\Python Scripts\\\\Data\\\\enwiki-latest-pages-articles1.xml-p1p41242.bz2\"\n",
        "out_path = \"C:\\\\Users\\\\Paul\\\\Documents\\\\Python Scripts\\\\Data\\\\Wiki Corpus\"\n",
        "\n",
        "# Create corpus!\n",
        "make_corpus(in_path, out_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'make_corpus' is not defined",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-3-24fb57d3dadc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Create corpus!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmake_corpus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m: name 'make_corpus' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oirCM0kxkgv"
      },
      "source": [
        "Now that the corpus is created, we also need to create a function to read the corpus from the files we created."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2y1fthbUxkgv"
      },
      "source": [
        "def read_corpus(corpus_directory):\n",
        "    \"\"\"\n",
        "    Function that iteratively reads the saved articles from the corpus directory\n",
        "    and appends the text to a list.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    @param corpus_directory: str,\n",
        "        A valid string specifying the path to the local directory in which the \n",
        "        files were saved using make_corpus().\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    @return corpus, list\n",
        "        A list containing the text of an article in each element.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Initialize empty corpus list\n",
        "    corpus = []\n",
        "    \n",
        "    # For each file in the corpus directory, do...\n",
        "    print(\"Reading local corpus, please wait...\")\n",
        "\n",
        "    for filename in os.listdir(corpus_directory):\n",
        "        file = open(f'{corpus_directory}/{filename}', 'r',\n",
        "                    encoding=\"utf8\")\n",
        "        article_text = file.read()\n",
        "        corpus.append(article_text)\n",
        "        \n",
        "    # Done, return\n",
        "    print(\"Done!\")\n",
        "    return corpus"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "EJaX5viHxkgv",
        "outputId": "aba219c9-2b5d-4b95-efa7-2300b1436651"
      },
      "source": [
        "# Read corpus! \n",
        "corpus = read_corpus(f'{PATH}/Wiki Corpus/')\n",
        "\n",
        "# Look at some example...\n",
        "corpus[3][0:100]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading local corpus, please wait...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'anarchism is political philosophy and movement that is sceptical of authority and rejects all involu'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_vMqfPMxkgw"
      },
      "source": [
        "### **BM25 Implementation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqMNon0Vxkgw"
      },
      "source": [
        "The first Information Retrieval method we try is the **BM25** method, which is a TF-IDF method, that retrieves the article that has the highest score based on the query given. \n",
        "\n",
        "Given, a document $D$ and a $Q$ that contains keywords $q_1,..., q_n$, we define the BM25 score of the document $D$ as:\n",
        "\n",
        "$$\n",
        "score(D, Q) = \\sum_{i = 1}^n IDF(q_i) \\cdot \\frac{TF(q_i, D) \\cdot (k_1 + 1)}{TF(q_i, D) + k_1 \\cdot \\left(1 - b + b \\cdot \\frac{|D|}{avgdl} \\right)}\n",
        "$$\n",
        "\n",
        "where: \n",
        "- $TF(q_i, D)$ is the *text frequency* of keyword $q_i$ in document $D$,\n",
        "- $IDF(q_i)$ is the *inverse document frequency* of keyword $q_i$, using the well-known definition,\n",
        "- $|D|$ is the length of the document $D$ in words.\n",
        "- $avgdl$ is the average document length in words in the whole corpus.\n",
        "- $k_1$ and $b$ are free parameters that are chosen rather than estimated, and which are usually chosen as $k_1 \\in [1.2, 2.0]$ and $b = 0.75$. These may also be chosen based on some advanced optimization.\n",
        "\n",
        "After computing the BM25 score of each document, which gives the relevance of each document to the given query, we sort the documents in descending order from most relevant to least relevant.\n",
        "\n",
        "On the implementation side, we use `Rank-BM25` library developed by Dorian Brown (https://github.com/dorianbrown/rank_bm25), and which implements different variants of the BM25 algorithm. It can be easily installed using `pip install rank-bm25`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EH8byUmmxkgw"
      },
      "source": [
        "# Tokenize the corpus\n",
        "tokenized_corpus = [doc.split(\" \") for doc in corpus]\n",
        "\n",
        "# Instantiate BM25 object from the tokenized corpus\n",
        "bm25 = BM25Okapi(tokenized_corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfumgpPIxkgx"
      },
      "source": [
        "Now we create  a simple function that a takes a string query, and a number `n` of required results, and returns the `n` most relevant results from our corpus:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doFTbRAcxkgx"
      },
      "source": [
        "def bm25okapi_search(tokenized_query, bm25, corpus, n_results = 1):\n",
        "    \"\"\"\n",
        "    Function that takes a tokenized query and prints the first 100 words of the \n",
        "    n_results most relevant results found in the corpus, based on the BM25\n",
        "    method.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    @param tokenized_query: list, array-like\n",
        "        A valid list containing the tokenized query.\n",
        "    @param bm25: BM25 object,\n",
        "        A valid object of type BM25 (BM25Okapi or BM25Plus) from the library\n",
        "        `rank-bm25`, initialized with a valid corpus.\n",
        "    @param corpus: list, array-like\n",
        "        A valid list containing the corpus from which the BM25 object has been \n",
        "        initialized. As returned from function read_corpus().\n",
        "    @param n_results: int, default = 1\n",
        "        The number of top results to print.\n",
        "    \"\"\"\n",
        "    \n",
        "    # We skip checking validity of arguments for now... We assume the user \n",
        "    # knows what they're doing.\n",
        "    \n",
        "    # Get top results for the query\n",
        "    top_results = bm25.get_top_n(tokenized_query, corpus, n = n_results)\n",
        "    \n",
        "    # Take only first 100 words from each result\n",
        "    top_results_100words = [' '.join(top_result.split(' ')[0:100]) \n",
        "                             for top_result in top_results]\n",
        "    \n",
        "    # Print results\n",
        "    print(f'Query: \"{query}\"\\n')\n",
        "    print(f'Top {n_results} results from Wikipedia:\\n\\n')\n",
        "    i = 1\n",
        "    for result in top_results_100words: \n",
        "        print(f'{i}. {result}\\n\\n')\n",
        "        i = i + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkbL85nhxkgx"
      },
      "source": [
        "As we know the topics of some of the articles included, we implement some queries about these topics and see whether their relevant articles are returned. Some of these topics included:\n",
        "- Autism\n",
        "- Anarchism \n",
        "- ATM \n",
        "\n",
        "We first try to implement some simple queries that include only the title of the article, and see if the relevant article is returned."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LP5cZkp_xkgy",
        "outputId": "03a687cd-43d7-4090-dea4-015eec7e97f0"
      },
      "source": [
        "query = \"autism\"\n",
        "tokenized_query = query.split(\" \")\n",
        "bm25okapi_search(tokenized_query = tokenized_query,\n",
        "                 bm25 = bm25, \n",
        "                 corpus = corpus,\n",
        "                 n_results = 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Query: \"autism\"\n",
            "\n",
            "Top 5 results from Wikipedia:\n",
            "\n",
            "\n",
            "1. autism is developmental disorder characterized by difficulties with social interaction and communication and by restricted and repetitive behavior parents often notice signs during the first three years of their child life these signs often develop gradually though some children with autism experience worsening in their communication and social skills after reaching developmental milestones at normal pace autism is associated with combination of genetic and environmental factors risk factors during pregnancy include certain infections such as rubella toxins including valproic acid alcohol cocaine pesticides lead and air pollution fetal growth restriction and autoimmune diseases controversies surround other proposed environmental causes for\n",
            "\n",
            "\n",
            "2. alfonso cuarón born november is mexican film director screenwriter producer cinematographer and editor his other notable films from variety of film genres including the family drama little princess the romantic drama great expectations the coming of age road comedy film tu mamá también the fantasy film harry potter and the prisoner of azkaban and the science fiction dystopian thriller children of men several of his films have received critical acclaim and accolades he has been nominated for academy awards winning four of them including two best director awards for gravity and roma he is the first latin american director to\n",
            "\n",
            "\n",
            "3. asa as an abbreviation or initialism may refer to biology and medicine accessible surface area of biomolecule accessible to solvent acetylsalicylic acid aspirin advanced surface ablation refractive eye surgery anterior spinal artery the blood vessel which supplies the anterior portion of the spinal cord aciduria disorder of the urea cycle asa physical status classification system rating of patients undergoing anesthesia education african studies association of the united kingdom african studies association albany students association at massey university auckland new zealand alexander smith academy in houston texas alpha sigma alpha national sorority american society for aesthetics american student assistance american studies\n",
            "\n",
            "\n",
            "4. the americans with disabilities act of or ada is civil rights law that prohibits discrimination based on disability it affords similar protections against discrimination to americans with disabilities as the civil rights act of which made discrimination based on race religion sex national origin and other characteristics illegal and later sexual orientation in addition unlike the civil rights act the ada also requires covered employers to provide reasonable accommodations to employees with disabilities and imposes accessibility requirements on public accommodations in the national council on disability had recommended the enactment of an americans with disabilities act ada and drafted the\n",
            "\n",
            "\n",
            "5. events the battle of hormozdgan is fought ardashir defeats and kills artabanus effectively ending the parthian empire emperor constantius ii enters rome for the first time to celebrate his victory over magnus magnentius assassination of conrad of montferrat conrad king of jerusalem in tyre two days after his title to the throne is confirmed by election the killing is carried out by hashshashin nichiren japanese buddhist monk propounds namu myōhō renge kyō for the very first time and declares it to be the essence of buddhism in effect founding nichiren buddhism the battle of cerignola is fought it is noted\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbFX0kUoxkgy",
        "outputId": "3a2f7081-7d9e-49a7-e451-789736d97714"
      },
      "source": [
        "query = \"anarchism\"\n",
        "tokenized_query = query.split(\" \")\n",
        "bm25okapi_search(tokenized_query = tokenized_query,\n",
        "                 bm25 = bm25, \n",
        "                 corpus = corpus,\n",
        "                 n_results = 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Query: \"anarchism\"\n",
            "\n",
            "Top 5 results from Wikipedia:\n",
            "\n",
            "\n",
            "1. anarchism is political philosophy and movement that is sceptical of authority and rejects all involuntary coercive forms of hierarchy anarchism calls for the abolition of the state which it holds to be undesirable unnecessary and harmful it is usually described alongside libertarian marxism as the libertarian wing libertarian socialism of the socialist movement and as having historical association with anti capitalism and socialism the history of anarchism goes back to prehistory when humans arguably lived in anarchistic societies long before the establishment of formal states realms or empires with the rise of organised hierarchical bodies scepticism toward authority also rose\n",
            "\n",
            "\n",
            "2. anarcho capitalism is political philosophy and economic theory that advocates the elimination of centralized states in favor of system of private property enforced by private agencies free markets and the right libertarian interpretation of self ownership which extends the concept to include control of private property as part of the self in the absence of statute anarcho capitalists hold that society tends to contractually self regulate and civilize through participation in the free market which they describe as voluntary society anarcho capitalists support wage labour and believe that neither protection of person and property nor victim compensation requires state in\n",
            "\n",
            "\n",
            "3. ayn rand born alisa zinovyevna rosenbaum march was russian american writer and philosopher she is known for her two best selling novels the fountainhead and atlas shrugged and for developing philosophical system she named objectivism born and educated in russia she moved to the united states in she had play produced on broadway in and after two early novels that were initially unsuccessful she achieved fame with her novel the fountainhead in rand published her best known work the novel atlas shrugged afterward she turned to non fiction to promote her philosophy publishing her own periodicals and releasing several collections\n",
            "\n",
            "\n",
            "4. events the battle of hormozdgan is fought ardashir defeats and kills artabanus effectively ending the parthian empire emperor constantius ii enters rome for the first time to celebrate his victory over magnus magnentius assassination of conrad of montferrat conrad king of jerusalem in tyre two days after his title to the throne is confirmed by election the killing is carried out by hashshashin nichiren japanese buddhist monk propounds namu myōhō renge kyō for the very first time and declares it to be the essence of buddhism in effect founding nichiren buddhism the battle of cerignola is fought it is noted\n",
            "\n",
            "\n",
            "5. events pope eusebius is banished by the emperor maxentius to sicily where he dies perhaps from hunger strike pope leo ii begins his pontificate byzantine bulgarian wars battle of the gates of trajan the bulgarians under the comitopuli samuel and aron defeat the byzantine forces at the gate of trajan with byzantine emperor basil ii barely escaping georgenberg pact ottokar iv duke of styria and leopold duke of austria sign heritage agreement in which ottokar gives his duchy to leopold and to his son frederick under the stipulation that austria and styria would henceforth remain undivided karl topia the ruler\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YdUabwRxkgy",
        "outputId": "909668c9-a3a0-494f-c1c4-73bf0e72e202"
      },
      "source": [
        "query = \"ATM\"\n",
        "tokenized_query = query.split(\" \")\n",
        "bm25okapi_search(tokenized_query = tokenized_query,\n",
        "                 bm25 = bm25, \n",
        "                 corpus = corpus,\n",
        "                 n_results = 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Query: \"ATM\"\n",
            "\n",
            "Top 5 results from Wikipedia:\n",
            "\n",
            "\n",
            "1. events the battle of hormozdgan is fought ardashir defeats and kills artabanus effectively ending the parthian empire emperor constantius ii enters rome for the first time to celebrate his victory over magnus magnentius assassination of conrad of montferrat conrad king of jerusalem in tyre two days after his title to the throne is confirmed by election the killing is carried out by hashshashin nichiren japanese buddhist monk propounds namu myōhō renge kyō for the very first time and declares it to be the essence of buddhism in effect founding nichiren buddhism the battle of cerignola is fought it is noted\n",
            "\n",
            "\n",
            "2. an abscess is collection of pus that has built up within the tissue of the body signs and symptoms of abscesses include redness pain warmth and swelling the swelling may feel fluid filled when pressed the area of redness often extends beyond the swelling carbuncles and boils are types of abscess that often involve hair follicles with carbuncles being larger they are usually caused by bacterial infection often many different types of bacteria are involved in single infection in the united states and many other areas of the world the most common bacteria present is methicillin resistant staphylococcus aureus rarely\n",
            "\n",
            "\n",
            "3. the alan parsons project were british rock band active between and whose core membership consisted of alan parsons and eric woolfson they were accompanied by varying number of session musicians and some relatively consistent session players such as guitarist ian bairnson arranger andrew powell bassist and vocalist david paton drummer stuart elliott and vocalists lenny zakatek and chris rainbow parsons was an audio engineer and producer by profession but also musician and composer songwriter by profession woolfson was also composer pianist and singer almost all the songs on the project albums are credited to woolfson parsons the alan parsons project\n",
            "\n",
            "\n",
            "4. the atanasoff berry computer abc was the first automatic electronic digital computer limited by the technology of the day and execution the device has remained somewhat obscure the abc priority is debated among historians of computer technology because it was neither programmable nor turing complete the first real programmable and turing complete machines the and the colossus computer from used similar valve based technology as abc overview conceived in the machine was built by iowa state college mathematics and physics professor john vincent atanasoff with the help of graduate student clifford berry it was designed only to solve systems of\n",
            "\n",
            "\n",
            "5. peas are an annual plant an annual plant is plant that completes its life cycle from germination to the production of seeds within one growing season and then dies the length of growing seasons and period in which they take place vary according to geographical location and may not correspond to the four traditional seasonal divisions of the year with respect to the traditional seasons annual plants are generally categorized into summer annuals and winter annuals summer annuals germinate during spring or early summer and mature by autumn of the same year winter annuals germinate during the autumn and mature\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6eH00gp28XO"
      },
      "source": [
        "### **BERT-Based Implementation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOWPQjR_3Aam"
      },
      "source": [
        "Following Nogueira and Cho's (2019) method, we try to implement BERT as a document re-ranker that will rank the relevance of the documents in the corpus with respect to a given query. \r\n",
        "\r\n",
        "As we know, BERT for classification tasks takes two sentences as input. Given a document $D$ and a query $Q$ that have been tokenized using a BERT tokenizer, we concatenate the query (Sentence 1) and the document (Sentence 2) together, separating them with a `[CLS]` classification token, and feed them to the original pre-trained BERT model implement as a binary classifier where the two classes are: \r\n",
        "\r\n",
        "$$\r\n",
        "\\begin{cases}\r\n",
        "0 = \\text{not relevant}, \\\\\r\n",
        "1 = \\text{relevant}\r\n",
        "\\end{cases}\r\n",
        "$$\r\n",
        "\r\n",
        "As such, BERT will return the probability of document $D$ being relevant to the query $Q$. Given a certain query $Q$, we apply this method on all documents $D_1, D_2, ..., D_n$ in the corpus and get a *relevance score* for each of them. The documents are then ranked by their obtained scores from most relevant to least relevant (similarly to BM25) and this will be the result of our information retrieval task.\r\n",
        "\r\n",
        "First we start by preparing everything for the model:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05ADn7H39EQe"
      },
      "source": [
        "We retrieve the BERT configurations directory from official Google servers, and read the BERT configs from `json` file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybWkIjUC8bBf",
        "outputId": "32b69904-c182-4c9f-e15a-81e419f87d87"
      },
      "source": [
        "# Retrieve BERT configs directory from official Google servers\r\n",
        "gs_folder_bert = \"gs://cloud-tpu-checkpoints/bert/keras_bert/uncased_L-12_H-768_A-12\"\r\n",
        "\r\n",
        "# Let's take a look at the content of the directory\r\n",
        "tf.io.gfile.listdir(gs_folder_bert)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bert_config.json',\n",
              " 'bert_model.ckpt.data-00000-of-00001',\n",
              " 'bert_model.ckpt.index',\n",
              " 'vocab.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCwx3EQn84MA",
        "outputId": "6a54c3c1-a323-4f18-f1b2-f06fdef8ae03"
      },
      "source": [
        "# Read BERT configs\r\n",
        "bert_config_file = os.path.join(gs_folder_bert, 'bert_config.json')\r\n",
        "config_dict = json.loads(tf.io.gfile.GFile(bert_config_file).read())\r\n",
        "bert_config = bert.configs.BertConfig.from_dict(config_dict)\r\n",
        "\r\n",
        "# Take a look at the BERT configs\r\n",
        "config_dict"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_probs_dropout_prob': 0.1,\n",
              " 'hidden_act': 'gelu',\n",
              " 'hidden_dropout_prob': 0.1,\n",
              " 'hidden_size': 768,\n",
              " 'initializer_range': 0.02,\n",
              " 'intermediate_size': 3072,\n",
              " 'max_position_embeddings': 512,\n",
              " 'num_attention_heads': 12,\n",
              " 'num_hidden_layers': 12,\n",
              " 'type_vocab_size': 2,\n",
              " 'vocab_size': 30522}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuJj7Z9P-kk0"
      },
      "source": [
        "Now set up the BERT tokenizer that will be used to tokenize both the Wikipedia articles and the queries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zB9T28RY8jCj",
        "outputId": "7d7b5476-003a-4181-e39e-43637c6c7a47"
      },
      "source": [
        "tokenizer = bert.tokenization.FullTokenizer(\r\n",
        "    vocab_file = os.path.join(gs_folder_bert, 'vocab.txt'),\r\n",
        "    do_lower_case = True\r\n",
        ")\r\n",
        "\r\n",
        "print('Vocab size: ', len(tokenizer.vocab))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size:  30522\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEmK2D3c_FdU"
      },
      "source": [
        "Now, we create functions that will tokenize, encode and prepare our text to be fed into BERT for scoring:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQ85CUq18jEH"
      },
      "source": [
        "def encode_text(text, tokenizer):\r\n",
        "    \"\"\"\r\n",
        "    Function that takes a text string and a BERT-compatible tokenizer\r\n",
        "    and returns the tokenized text with the '[SEP]' flag appended, \r\n",
        "    after taking a subset of the tokens' list in order to stay under \r\n",
        "    the 512 BERT max sequence length.\r\n",
        "\r\n",
        "    This function is a utility function for the following 'bert_encode' function.\r\n",
        "\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    @param text: str,\r\n",
        "        A valid string of text to be tokenized\r\n",
        "    @param tokenizer: BERT.tokenization function,\r\n",
        "        A valid BERT-compatible tokenizer\r\n",
        "\r\n",
        "    Returns\r\n",
        "    -------\r\n",
        "    @return tokenized text, list\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    # Retrieve tokens from tokenizer\r\n",
        "    tokens = list(tokenizer.tokenize(text))\r\n",
        "    # Take only the first 450 elements\r\n",
        "    tokens = tokens[0:450]\r\n",
        "    # Append [SEP]\r\n",
        "    tokens.append('[SEP]')\r\n",
        "    return tokenizer.convert_tokens_to_ids(tokens)\r\n",
        "\r\n",
        "def bert_encode(corpus, query, tokenizer):\r\n",
        "    \"\"\"\r\n",
        "    Function that takes a corpus, a query and a tokenizer and returns the \r\n",
        "    query and all texts in the corpus concatenated together and separated by\r\n",
        "    [CLS] flag, then tokenized and ready for BERT.\r\n",
        "\r\n",
        "    This function utilizes the previous utility function 'encode_text'.\r\n",
        "\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    @param corpus: list,\r\n",
        "        A valid list of string elements where each element is an article in our\r\n",
        "        corpus. As returned from 'read_corpus' function.\r\n",
        "    @param query: string,\r\n",
        "        A valid text string which is the query for which answers need to be \r\n",
        "        retrieved.\r\n",
        "    @param tokenizer: BERT.tokenization function,\r\n",
        "        A valid BERT-compatible tokenizer.\r\n",
        "\r\n",
        "    Returns\r\n",
        "    -------\r\n",
        "    @return inputs: dict,\r\n",
        "        A dictionary containg three elements: \r\n",
        "            - input_word_ids: TF.io.tensor, \r\n",
        "                    The tokenized words ids.\r\n",
        "            - input_mask: TF.io.tensor,\r\n",
        "                    Tensor taking values based on whether the element at each \r\n",
        "                    position is a mask (flag) or not.\r\n",
        "            - input_type_ids: TF.io.tensor,\r\n",
        "                    Tensor taking values based on the type of the input element\r\n",
        "                    at each position.\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    # Compute corpus length.\r\n",
        "    corpus_length = len(corpus)\r\n",
        "\r\n",
        "    # Transform each article in the corpus to a TF ragged constant.\r\n",
        "    tf_corpus = tf.ragged.constant(\r\n",
        "        [encode_text(article, tokenizer) for article in corpus]\r\n",
        "        )\r\n",
        "\r\n",
        "    # Encode the query, then transform it to a TF ragged constant of same \r\n",
        "    # length as the corpus.\r\n",
        "    encoded_query = encode_text(query, tokenizer)\r\n",
        "    tf_query = tf.ragged.constant(\r\n",
        "        [encoded_query for i in range(corpus_length)]\r\n",
        "        )\r\n",
        "    \r\n",
        "    # Create as many [CLS] flags as the number of articles in the corpus.\r\n",
        "    cls = [tokenizer.convert_tokens_to_ids(['[CLS]'])] * tf_corpus.shape[0]\r\n",
        "    # Concatenate all elements together \r\n",
        "    input_word_ids = tf.concat([cls, tf_query, tf_corpus], axis = -1)\r\n",
        "\r\n",
        "    # Create masks tensor...\r\n",
        "    input_mask = tf.ones_like(input_word_ids).to_tensor()\r\n",
        "\r\n",
        "    # Create types tensors...\r\n",
        "    type_cls = tf.zeros_like(cls)\r\n",
        "    type_corpus = tf.zeros_like(tf_corpus)\r\n",
        "    type_query = tf.zeros_like(tf_query)\r\n",
        "    # ... and concatenate them together\r\n",
        "    input_type_ids = tf.concat(\r\n",
        "        [type_cls, type_query, type_corpus],\r\n",
        "        axis = -1\r\n",
        "    ).to_tensor()\r\n",
        "\r\n",
        "    # Prepare results dictionary for returning...\r\n",
        "    inputs = {\r\n",
        "        'input_word_ids' : input_word_ids.to_tensor(),\r\n",
        "        'input_mask' : input_mask,\r\n",
        "        'input_type_ids' : input_type_ids\r\n",
        "    }\r\n",
        "\r\n",
        "    # Return...\r\n",
        "    return inputs"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWIqC5_zDNgR"
      },
      "source": [
        "Let's try our function and see if they work properly:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IU9asPSf8jHs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a83e8158-cb37-4d36-a79b-1c3b6eafe599"
      },
      "source": [
        "text = 'this is a text to test our functions'\r\n",
        "\r\n",
        "# Try...\r\n",
        "encode_text(text, tokenizer)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2023, 2003, 1037, 3793, 2000, 3231, 2256, 4972, 102]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpiNIMdBDzt5"
      },
      "source": [
        "Now let's try to tokenize and encode our full corpus with a given query and take a look at the specifications of the obtained results:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H55fwe_k8jJW"
      },
      "source": [
        "query_data1 = bert_encode(\r\n",
        "    corpus = corpus,\r\n",
        "    query = 'anarchism',\r\n",
        "    tokenizer = tokenizer\r\n",
        ")"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-6OjTLtFTP_",
        "outputId": "954f98cc-2777-4878-c9f7-7c270bab5272"
      },
      "source": [
        "for key, value in query_data1.items():\r\n",
        "  print(f'{key:15s} shape: {value.shape}')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_word_ids  shape: (1000, 456)\n",
            "input_mask      shape: (1000, 456)\n",
            "input_type_ids  shape: (1000, 456)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-PJ8x17GwML"
      },
      "source": [
        "Everything looks working great!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXrrywpnH7io"
      },
      "source": [
        "#### **Note on BERT**\r\n",
        "\r\n",
        "As we know, the corpus on which BERT has been trained contains the **full English Wikipedia** (2,500M words) along with the BooksCorpus (800M words).\r\n",
        "\r\n",
        "For this reason, we thought that we do not need to re-train and finetune BERT for our scoring task, since it has already seen the articles found in our corpus. Being trained on document-level corpus and not word-based ones, BERT would be able to idenitfy the connections between our queries and the articles available in the small corpus that we have.\r\n",
        "\r\n",
        "Furthermore, finetuning BERT would require training again on query-answers data sets such as [**MSMARCO**](https://microsoft.github.io/msmarco/) or [**TREC-CAR**](https://trec.nist.gov/pubs/trec26/papers/Overview-CAR.pdf), which were used by Nogueira and Cho (2019) in their implementation. However, due to network constraints (downloading the huge data sets proved not possible) and computational constraints, as well as time constraints (according to Nogueira and Cho, finetuning BERT required more than 30 hours of training), we were unable to finetune it to our specific task. We assumed that it may provide good reasults 'out-of-the-box', however, experimental results have shown otherwise:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9LXdqPAMMp-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxyH24i2MMoO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9N6r-a0H6lK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "na9ghnq16vIP"
      },
      "source": [
        "# Import local modules\r\n",
        "import metrics\r\n",
        "import modeling\r\n",
        "import optimization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3p44Bg9G1GW",
        "outputId": "8c4eb938-15c6-4a52-f663-b0caa272a9e8"
      },
      "source": [
        "pip install -q tf-models-official==2.3.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 849kB 4.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 7.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 36.7MB 1.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 174kB 42.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 358kB 41.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 394.7MB 38kB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 38.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 10.6MB 24.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 471kB 39.0MB/s \n",
            "\u001b[?25h  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFN28CL4HLpt"
      },
      "source": [
        "import os\r\n",
        "\r\n",
        "from official.modeling import tf_utils\r\n",
        "from official import nlp\r\n",
        "from official.nlp import bert\r\n",
        "\r\n",
        "# Load the required submodules\r\n",
        "import official.nlp.optimization\r\n",
        "import official.nlp.bert.bert_models\r\n",
        "import official.nlp.bert.configs\r\n",
        "import official.nlp.bert.run_classifier\r\n",
        "import official.nlp.bert.tokenization\r\n",
        "import official.nlp.data.classifier_data_lib\r\n",
        "import official.nlp.modeling.losses\r\n",
        "import official.nlp.modeling.models\r\n",
        "import official.nlp.modeling.networks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oB2dY1vGEAg",
        "outputId": "88f21746-eee2-4068-93ef-55497d9092c3"
      },
      "source": [
        "# Retrieve BERT configs\r\n",
        "gs_folder_bert = \"gs://cloud-tpu-checkpoints/bert/keras_bert/uncased_L-12_H-768_A-12\"\r\n",
        "tf.io.gfile.listdir(gs_folder_bert)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bert_config.json',\n",
              " 'bert_model.ckpt.data-00000-of-00001',\n",
              " 'bert_model.ckpt.index',\n",
              " 'vocab.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRH18ihHGMNM",
        "outputId": "1382dc62-2883-4432-9750-1bfcb904dd90"
      },
      "source": [
        "# Set up BERT tokenizer to generate TensorFlow dataset\r\n",
        "tokenizer = bert.tokenization.FullTokenizer(\r\n",
        "    vocab_file = os.path.join(gs_folder_bert, 'vocab.txt'),\r\n",
        "    do_lower_case = True\r\n",
        ")\r\n",
        "\r\n",
        "print(\"Vocab size: \", len(tokenizer.vocab))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size:  30522\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYbOcTCwIrEa",
        "outputId": "e49707c7-7a7f-401a-d9fb-d1cd2f5a5324"
      },
      "source": [
        "# Let's tokenize some article from our corpus\r\n",
        "tokens = tokenizer.tokenize(corpus[0][0:10])\r\n",
        "print(tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['this', 'is', 'li']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmoOIErVJH0u"
      },
      "source": [
        "# Create function to append the [SEP] flag and encode each article\r\n",
        "def encode_article(article):\r\n",
        "    tokens = list(tokenizer.tokenize(article))\r\n",
        "    # Append [SEP]\r\n",
        "    tokens.append('[SEP]')\r\n",
        "    print(tokens)\r\n",
        "    return tokenizer.convert_tokens_to_ids(tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9i12oNWRp7A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc1a6cf0-ab3b-49b5-ed2d-e5f62b1dfbaf"
      },
      "source": [
        "query = \"what is autism?\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['what', 'is', 'autism', '?', '[SEP]']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2054, 2003, 19465, 1029, 102]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0GVNI7HR1xA",
        "outputId": "10bc1bcc-1197-4ca5-c61e-5886d6b80026"
      },
      "source": [
        "article = corpus[0]\r\n",
        "print(article)\r\n",
        "\r\n",
        "_ = encode_article(article)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "this is list of characters in ayn rand novel atlas shrugged major characters the following are major characters from the novel protagonists dagny taggart dagny taggart is the protagonist of the novel she is vice president in charge of operations for taggart under her brother james taggart given james incompetence dagny is responsible for all the workings of the railroad francisco anconia francisco anconia is one of the central characters in atlas shrugged an owner by inheritance of the world largest copper mining operation he is childhood friend and the first love of dagny taggart child prodigy of exceptional talents francisco was dubbed the climax of the anconia line an already prestigious family of skilled industrialists he was classmate of john galt and ragnar danneskjöld and student of both hugh akston and robert stadler he began working while still in school proving that he could have made fortune without the aid of his family wealth and power later francisco bankrupts the anconia business to put it out of others reach his full name is given as francisco domingo carlos andres sebastián anconia john galt john galt is the primary male hero of atlas shrugged he initially appears as an unnamed menial worker for taggart who often dines with eddie willers in the employees cafeteria and leads eddie to reveal important information about dagny taggart and taggart only eddie side of their conversations is given in the novel later in the novel the reader discovers this worker true identity before working for taggart galt worked as an engineer for the twentieth century motor company where he secretly invented generator of usable electric energy from ambient static electricity but abandoned his prototype and his employment when dissatisfied by an easily corrupted novel system of payment this prototype was found by dagny taggart and hank rearden galt himself remains concealed throughout much of the novel working job and living by himself where he unites the most skillful inventors and business leaders under his leadership much of the book third division is given to his broadcast speech which presents the author philosophy of objectivism henry hank rearden henry known as hank rearden is one of the central characters in atlas shrugged he owns the most important steel company in the united states and invents rearden metal an alloy stronger lighter cheaper and tougher than steel he lives in philadelphia with his wife lillian his brother philip and his elderly mother rearden represents type of self made man and eventually divorces lillian abandons his steel mills following bloody assault by government planted workers and joins john galt strike eddie willers edwin eddie willers is the special assistant to the vice president in charge of operations at taggart his father and grandfather worked for the taggarts and himself likewise he is completely loyal to dagny and to taggart willers does not possess the creative ability of galt associates but matches them in moral courage and is capable of appreciating and making use of their creations after dagny shifts her attention and loyalty to saving the captive galt willers maintains the railroad until its collapse ragnar danneskjöld one of galt first followers and world famous as pirate who seizes relief ships sent from the united states to the people states of europe he works to ensure that once those espousing galt philosophy are restored to their rightful place in society they have enough capital to rebuild the world kept in the background for much of the book danneskjöld makes personal appearance to encourage rearden to persevere in his increasingly difficult situation and gives him bar of gold as compensation for the income taxes he has paid over the last several years danneskjöld is married to the actress kay ludlow their relationship is kept hidden from the outside world which only knows of ludlow as retired film star considered misfit by galt other adherents he views his actions as means to speed the world along in understanding galt perspective according to barbara branden who was closely associated with rand at the time the book was written there were sections written describing danneskjöld adventures at sea cut from the final published text in comment at lecture ayn rand admitted that danneskjöld name was tribute to victor hugo novel wherein the hero becomes the first of the counts of danneskjöld in the published book danneskjöld is always seen through the eyes of others dagny taggart or hank rearden except for brief paragraph in the very last chapter antagonists james taggart the president of taggart and the book most important antagonist taggart is an expert influence peddler but incapable of making operational decisions on his own he relies on his sister dagny taggart to actually run the railroad but nonetheless opposes her in almost every endeavor because of his various anti capitalist moral and political beliefs in sense he is the antithesis of dagny this contradiction leads to the recurring absurdity of his life the desire to overcome those on whom his life depends and the horror that he will succeed at this in the final chapters of the novel he suffers complete mental breakdown upon realizing that he can no longer deceive himself in this respect lillian rearden the unsupportive wife of hank rearden who dislikes his habits and secretly at first seeks to ruin rearden to prove her own value lillian achieves this when she passes information to james taggart about her husband affair with his sister this information is used to persuade rearden to sign gift certificate which delivers all the property rights of rearden metal to others lillian thereafter uses james taggart for sexual satisfaction until hank abandons her dr floyd ferris ferris is biologist who works as co ordinator at the state science institute he uses his position there to deride reason and productive achievement and publishes book entitled why do you think you think he clashes on several occasions with hank rearden and twice attempts to blackmail rearden into giving up rearden metal he is\n",
            "['this', 'is', 'list', 'of', 'characters', 'in', 'a', '##yn', 'rand', 'novel', 'atlas', 'shrugged', 'major', 'characters', 'the', 'following', 'are', 'major', 'characters', 'from', 'the', 'novel', 'protagonists', 'da', '##gny', 'tag', '##gart', 'da', '##gny', 'tag', '##gart', 'is', 'the', 'protagonist', 'of', 'the', 'novel', 'she', 'is', 'vice', 'president', 'in', 'charge', 'of', 'operations', 'for', 'tag', '##gart', 'under', 'her', 'brother', 'james', 'tag', '##gart', 'given', 'james', 'inc', '##omp', '##ete', '##nce', 'da', '##gny', 'is', 'responsible', 'for', 'all', 'the', 'workings', 'of', 'the', 'railroad', 'francisco', 'an', '##con', '##ia', 'francisco', 'an', '##con', '##ia', 'is', 'one', 'of', 'the', 'central', 'characters', 'in', 'atlas', 'shrugged', 'an', 'owner', 'by', 'inheritance', 'of', 'the', 'world', 'largest', 'copper', 'mining', 'operation', 'he', 'is', 'childhood', 'friend', 'and', 'the', 'first', 'love', 'of', 'da', '##gny', 'tag', '##gart', 'child', 'prodigy', 'of', 'exceptional', 'talents', 'francisco', 'was', 'dubbed', 'the', 'climax', 'of', 'the', 'an', '##con', '##ia', 'line', 'an', 'already', 'prestigious', 'family', 'of', 'skilled', 'industrialist', '##s', 'he', 'was', 'classmate', 'of', 'john', 'gal', '##t', 'and', 'rag', '##nar', 'dan', '##nes', '##k', '##jo', '##ld', 'and', 'student', 'of', 'both', 'hugh', 'ak', '##ston', 'and', 'robert', 'st', '##ad', '##ler', 'he', 'began', 'working', 'while', 'still', 'in', 'school', 'proving', 'that', 'he', 'could', 'have', 'made', 'fortune', 'without', 'the', 'aid', 'of', 'his', 'family', 'wealth', 'and', 'power', 'later', 'francisco', 'bankrupt', '##s', 'the', 'an', '##con', '##ia', 'business', 'to', 'put', 'it', 'out', 'of', 'others', 'reach', 'his', 'full', 'name', 'is', 'given', 'as', 'francisco', 'domingo', 'carlos', 'andres', 'sebastian', 'an', '##con', '##ia', 'john', 'gal', '##t', 'john', 'gal', '##t', 'is', 'the', 'primary', 'male', 'hero', 'of', 'atlas', 'shrugged', 'he', 'initially', 'appears', 'as', 'an', 'unnamed', 'men', '##ial', 'worker', 'for', 'tag', '##gart', 'who', 'often', 'din', '##es', 'with', 'eddie', 'will', '##ers', 'in', 'the', 'employees', 'cafeteria', 'and', 'leads', 'eddie', 'to', 'reveal', 'important', 'information', 'about', 'da', '##gny', 'tag', '##gart', 'and', 'tag', '##gart', 'only', 'eddie', 'side', 'of', 'their', 'conversations', 'is', 'given', 'in', 'the', 'novel', 'later', 'in', 'the', 'novel', 'the', 'reader', 'discovers', 'this', 'worker', 'true', 'identity', 'before', 'working', 'for', 'tag', '##gart', 'gal', '##t', 'worked', 'as', 'an', 'engineer', 'for', 'the', 'twentieth', 'century', 'motor', 'company', 'where', 'he', 'secretly', 'invented', 'generator', 'of', 'usable', 'electric', 'energy', 'from', 'ambient', 'static', 'electricity', 'but', 'abandoned', 'his', 'prototype', 'and', 'his', 'employment', 'when', 'dissatisfied', 'by', 'an', 'easily', 'corrupted', 'novel', 'system', 'of', 'payment', 'this', 'prototype', 'was', 'found', 'by', 'da', '##gny', 'tag', '##gart', 'and', 'hank', 'rear', '##den', 'gal', '##t', 'himself', 'remains', 'concealed', 'throughout', 'much', 'of', 'the', 'novel', 'working', 'job', 'and', 'living', 'by', 'himself', 'where', 'he', 'unite', '##s', 'the', 'most', 'skill', '##ful', 'inventor', '##s', 'and', 'business', 'leaders', 'under', 'his', 'leadership', 'much', 'of', 'the', 'book', 'third', 'division', 'is', 'given', 'to', 'his', 'broadcast', 'speech', 'which', 'presents', 'the', 'author', 'philosophy', 'of', 'object', '##ivism', 'henry', 'hank', 'rear', '##den', 'henry', 'known', 'as', 'hank', 'rear', '##den', 'is', 'one', 'of', 'the', 'central', 'characters', 'in', 'atlas', 'shrugged', 'he', 'owns', 'the', 'most', 'important', 'steel', 'company', 'in', 'the', 'united', 'states', 'and', 'in', '##vent', '##s', 'rear', '##den', 'metal', 'an', 'alloy', 'stronger', 'lighter', 'cheaper', 'and', 'tough', '##er', 'than', 'steel', 'he', 'lives', 'in', 'philadelphia', 'with', 'his', 'wife', 'lillian', 'his', 'brother', 'philip', 'and', 'his', 'elderly', 'mother', 'rear', '##den', 'represents', 'type', 'of', 'self', 'made', 'man', 'and', 'eventually', 'divorce', '##s', 'lillian', 'abandon', '##s', 'his', 'steel', 'mills', 'following', 'bloody', 'assault', 'by', 'government', 'planted', 'workers', 'and', 'joins', 'john', 'gal', '##t', 'strike', 'eddie', 'will', '##ers', 'edwin', 'eddie', 'will', '##ers', 'is', 'the', 'special', 'assistant', 'to', 'the', 'vice', 'president', 'in', 'charge', 'of', 'operations', 'at', 'tag', '##gart', 'his', 'father', 'and', 'grandfather', 'worked', 'for', 'the', 'tag', '##gart', '##s', 'and', 'himself', 'likewise', 'he', 'is', 'completely', 'loyal', 'to', 'da', '##gny', 'and', 'to', 'tag', '##gart', 'will', '##ers', 'does', 'not', 'possess', 'the', 'creative', 'ability', 'of', 'gal', '##t', 'associates', 'but', 'matches', 'them', 'in', 'moral', 'courage', 'and', 'is', 'capable', 'of', 'app', '##re', '##cia', '##ting', 'and', 'making', 'use', 'of', 'their', 'creations', 'after', 'da', '##gny', 'shifts', 'her', 'attention', 'and', 'loyalty', 'to', 'saving', 'the', 'captive', 'gal', '##t', 'will', '##ers', 'maintains', 'the', 'railroad', 'until', 'its', 'collapse', 'rag', '##nar', 'dan', '##nes', '##k', '##jo', '##ld', 'one', 'of', 'gal', '##t', 'first', 'followers', 'and', 'world', 'famous', 'as', 'pirate', 'who', 'seize', '##s', 'relief', 'ships', 'sent', 'from', 'the', 'united', 'states', 'to', 'the', 'people', 'states', 'of', 'europe', 'he', 'works', 'to', 'ensure', 'that', 'once', 'those', 'es', '##po', '##using', 'gal', '##t', 'philosophy', 'are', 'restored', 'to', 'their', 'rightful', 'place', 'in', 'society', 'they', 'have', 'enough', 'capital', 'to', 'rebuild', 'the', 'world', 'kept', 'in', 'the', 'background', 'for', 'much', 'of', 'the', 'book', 'dan', '##nes', '##k', '##jo', '##ld', 'makes', 'personal', 'appearance', 'to', 'encourage', 'rear', '##den', 'to', 'per', '##se', '##vere', 'in', 'his', 'increasingly', 'difficult', 'situation', 'and', 'gives', 'him', 'bar', 'of', 'gold', 'as', 'compensation', 'for', 'the', 'income', 'taxes', 'he', 'has', 'paid', 'over', 'the', 'last', 'several', 'years', 'dan', '##nes', '##k', '##jo', '##ld', 'is', 'married', 'to', 'the', 'actress', 'kay', 'lu', '##dlow', 'their', 'relationship', 'is', 'kept', 'hidden', 'from', 'the', 'outside', 'world', 'which', 'only', 'knows', 'of', 'lu', '##dlow', 'as', 'retired', 'film', 'star', 'considered', 'mis', '##fi', '##t', 'by', 'gal', '##t', 'other', 'adherents', 'he', 'views', 'his', 'actions', 'as', 'means', 'to', 'speed', 'the', 'world', 'along', 'in', 'understanding', 'gal', '##t', 'perspective', 'according', 'to', 'barbara', 'brand', '##en', 'who', 'was', 'closely', 'associated', 'with', 'rand', 'at', 'the', 'time', 'the', 'book', 'was', 'written', 'there', 'were', 'sections', 'written', 'describing', 'dan', '##nes', '##k', '##jo', '##ld', 'adventures', 'at', 'sea', 'cut', 'from', 'the', 'final', 'published', 'text', 'in', 'comment', 'at', 'lecture', 'a', '##yn', 'rand', 'admitted', 'that', 'dan', '##nes', '##k', '##jo', '##ld', 'name', 'was', 'tribute', 'to', 'victor', 'hugo', 'novel', 'wherein', 'the', 'hero', 'becomes', 'the', 'first', 'of', 'the', 'counts', 'of', 'dan', '##nes', '##k', '##jo', '##ld', 'in', 'the', 'published', 'book', 'dan', '##nes', '##k', '##jo', '##ld', 'is', 'always', 'seen', 'through', 'the', 'eyes', 'of', 'others', 'da', '##gny', 'tag', '##gart', 'or', 'hank', 'rear', '##den', 'except', 'for', 'brief', 'paragraph', 'in', 'the', 'very', 'last', 'chapter', 'antagonist', '##s', 'james', 'tag', '##gart', 'the', 'president', 'of', 'tag', '##gart', 'and', 'the', 'book', 'most', 'important', 'antagonist', 'tag', '##gart', 'is', 'an', 'expert', 'influence', 'pe', '##ddle', '##r', 'but', 'incapable', 'of', 'making', 'operational', 'decisions', 'on', 'his', 'own', 'he', 'relies', 'on', 'his', 'sister', 'da', '##gny', 'tag', '##gart', 'to', 'actually', 'run', 'the', 'railroad', 'but', 'nonetheless', 'opposes', 'her', 'in', 'almost', 'every', 'endeavor', 'because', 'of', 'his', 'various', 'anti', 'capitalist', 'moral', 'and', 'political', 'beliefs', 'in', 'sense', 'he', 'is', 'the', 'anti', '##thesis', 'of', 'da', '##gny', 'this', 'contradiction', 'leads', 'to', 'the', 'recurring', 'absurd', '##ity', 'of', 'his', 'life', 'the', 'desire', 'to', 'overcome', 'those', 'on', 'whom', 'his', 'life', 'depends', 'and', 'the', 'horror', 'that', 'he', 'will', 'succeed', 'at', 'this', 'in', 'the', 'final', 'chapters', 'of', 'the', 'novel', 'he', 'suffers', 'complete', 'mental', 'breakdown', 'upon', 'realizing', 'that', 'he', 'can', 'no', 'longer', 'dec', '##ei', '##ve', 'himself', 'in', 'this', 'respect', 'lillian', 'rear', '##den', 'the', 'un', '##su', '##pp', '##ort', '##ive', 'wife', 'of', 'hank', 'rear', '##den', 'who', 'dislike', '##s', 'his', 'habits', 'and', 'secretly', 'at', 'first', 'seeks', 'to', 'ruin', 'rear', '##den', 'to', 'prove', 'her', 'own', 'value', 'lillian', 'achieve', '##s', 'this', 'when', 'she', 'passes', 'information', 'to', 'james', 'tag', '##gart', 'about', 'her', 'husband', 'affair', 'with', 'his', 'sister', 'this', 'information', 'is', 'used', 'to', 'persuade', 'rear', '##den', 'to', 'sign', 'gift', 'certificate', 'which', 'delivers', 'all', 'the', 'property', 'rights', 'of', 'rear', '##den', 'metal', 'to', 'others', 'lillian', 'thereafter', 'uses', 'james', 'tag', '##gart', 'for', 'sexual', 'satisfaction', 'until', 'hank', 'abandon', '##s', 'her', 'dr', 'floyd', 'ferris', 'ferris', 'is', 'biologist', 'who', 'works', 'as', 'co', 'or', '##dina', '##tor', 'at', 'the', 'state', 'science', 'institute', 'he', 'uses', 'his', 'position', 'there', 'to', 'der', '##ide', 'reason', 'and', 'productive', 'achievement', 'and', 'publishes', 'book', 'entitled', 'why', 'do', 'you', 'think', 'you', 'think', 'he', 'clashes', 'on', 'several', 'occasions', 'with', 'hank', 'rear', '##den', 'and', 'twice', 'attempts', 'to', 'blackmail', 'rear', '##den', 'into', 'giving', 'up', 'rear', '##den', 'metal', 'he', 'is', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFl08RN0SIPO"
      },
      "source": [
        "tf_corpus = tf.ragged.constant([\r\n",
        "    encode_article(article) for article in corpus                                \r\n",
        "])\r\n",
        "\r\n",
        "encoded_query = encode_article(query)\r\n",
        "tf_query = tf.ragged.constant([\r\n",
        "    encoded_query for i in range(len(corpus))\r\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1r9uHNVWN4O"
      },
      "source": [
        "def encode_article(article, tokenizer):\r\n",
        "    tokens = list(tokenizer.tokenize(article))\r\n",
        "    tokens = tokens[0:450]\r\n",
        "    # Append [SEP]\r\n",
        "    tokens.append('[SEP]')\r\n",
        "    return tokenizer.convert_tokens_to_ids(tokens)\r\n",
        "\r\n",
        "def bert_encode(corpus, query, tokenizer):\r\n",
        "    corpus_length = len(corpus)\r\n",
        "\r\n",
        "    tf_corpus = tf.ragged.constant(\r\n",
        "        [encode_article(article, tokenizer) for article in corpus]\r\n",
        "        )\r\n",
        "    encoded_query = encode_article(query, tokenizer)\r\n",
        "    tf_query = tf.ragged.constant(\r\n",
        "        [encoded_query for i in range(corpus_length)]\r\n",
        "        )\r\n",
        "    \r\n",
        "    cls = [tokenizer.convert_tokens_to_ids(['[CLS]'])] * tf_corpus.shape[0]\r\n",
        "    input_word_ids = tf.concat([cls, tf_query, tf_corpus], axis = -1)\r\n",
        "\r\n",
        "    input_mask = tf.ones_like(input_word_ids).to_tensor()\r\n",
        "\r\n",
        "    type_cls = tf.zeros_like(cls)\r\n",
        "    type_corpus = tf.zeros_like(tf_corpus)\r\n",
        "    type_query = tf.zeros_like(tf_query)\r\n",
        "    input_type_ids = tf.concat(\r\n",
        "        [type_cls, type_query, type_corpus],\r\n",
        "        axis = -1\r\n",
        "    ).to_tensor()\r\n",
        "\r\n",
        "    inputs = {\r\n",
        "        'input_word_ids' : input_word_ids.to_tensor(),\r\n",
        "        'input_mask' : input_mask,\r\n",
        "        'input_type_ids' : input_type_ids\r\n",
        "    }\r\n",
        "\r\n",
        "    return inputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K71W-k00YCQ6"
      },
      "source": [
        "my_examples = bert_encode(\r\n",
        "    corpus = corpus, \r\n",
        "    query = \"what is anarchism\",\r\n",
        "    tokenizer = tokenizer\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OQWuGL8aaRz",
        "outputId": "aabe8dc0-1251-43d1-d82b-f7a396f83353"
      },
      "source": [
        "for key, value in my_examples.items():\r\n",
        "  print(f'{key:15s} shape: {value.shape}')\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_word_ids  shape: (1000, 458)\n",
            "input_mask      shape: (1000, 458)\n",
            "input_type_ids  shape: (1000, 458)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhHX65wVZRYM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2o_5G5fXqxr",
        "outputId": "81d0240f-7dab-46d6-80b9-eb8b2d4df1b4"
      },
      "source": [
        "trying = {'input_type_ids' : my_examples['input_type_ids'][0:10],\r\n",
        "'input_mask' : my_examples['input_mask'][0:10],\r\n",
        "'input_word_ids': my_examples['input_word_ids'][0:10]}\r\n",
        "\r\n",
        "bert_classifier(trying, training = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10, 2), dtype=float32, numpy=\n",
              "array([[-0.08801941, -0.2442232 ],\n",
              "       [-0.08258021, -0.24441071],\n",
              "       [-0.07205202, -0.23794457],\n",
              "       [-0.08440991, -0.25573486],\n",
              "       [-0.08289999, -0.24607748],\n",
              "       [-0.08674547, -0.2470034 ],\n",
              "       [-0.07741472, -0.23748921],\n",
              "       [-0.08343688, -0.27366745],\n",
              "       [-0.07933323, -0.24567214],\n",
              "       [-0.06795169, -0.26091066]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbtY2u3_YHLI"
      },
      "source": [
        "result = bert_classifier(my_examples, training = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVGdb3_kW8t5",
        "outputId": "32fe8ae6-9c9b-40ad-c238-c3253ef2fe3f"
      },
      "source": [
        "# Predict in batches to avoid RAM overload\r\n",
        "results = []\r\n",
        "i = 0\r\n",
        "while i < 1000:\r\n",
        "    print(f'Scored {i + 5} examples!')\r\n",
        "    batch = {\r\n",
        "        'input_type_ids': my_examples['input_type_ids'][i:(i+5)],\r\n",
        "        'input_mask': my_examples['input_mask'][i:(i+5)],\r\n",
        "        'input_word_ids': my_examples['input_word_ids'][i:(i+5)]\r\n",
        "    }\r\n",
        "    result = bert_classifier(batch, training = False)\r\n",
        "    results.append(result)\r\n",
        "    i = i + 6"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scored 5 examples!\n",
            "Scored 11 examples!\n",
            "Scored 17 examples!\n",
            "Scored 23 examples!\n",
            "Scored 29 examples!\n",
            "Scored 35 examples!\n",
            "Scored 41 examples!\n",
            "Scored 47 examples!\n",
            "Scored 53 examples!\n",
            "Scored 59 examples!\n",
            "Scored 65 examples!\n",
            "Scored 71 examples!\n",
            "Scored 77 examples!\n",
            "Scored 83 examples!\n",
            "Scored 89 examples!\n",
            "Scored 95 examples!\n",
            "Scored 101 examples!\n",
            "Scored 107 examples!\n",
            "Scored 113 examples!\n",
            "Scored 119 examples!\n",
            "Scored 125 examples!\n",
            "Scored 131 examples!\n",
            "Scored 137 examples!\n",
            "Scored 143 examples!\n",
            "Scored 149 examples!\n",
            "Scored 155 examples!\n",
            "Scored 161 examples!\n",
            "Scored 167 examples!\n",
            "Scored 173 examples!\n",
            "Scored 179 examples!\n",
            "Scored 185 examples!\n",
            "Scored 191 examples!\n",
            "Scored 197 examples!\n",
            "Scored 203 examples!\n",
            "Scored 209 examples!\n",
            "Scored 215 examples!\n",
            "Scored 221 examples!\n",
            "Scored 227 examples!\n",
            "Scored 233 examples!\n",
            "Scored 239 examples!\n",
            "Scored 245 examples!\n",
            "Scored 251 examples!\n",
            "Scored 257 examples!\n",
            "Scored 263 examples!\n",
            "Scored 269 examples!\n",
            "Scored 275 examples!\n",
            "Scored 281 examples!\n",
            "Scored 287 examples!\n",
            "Scored 293 examples!\n",
            "Scored 299 examples!\n",
            "Scored 305 examples!\n",
            "Scored 311 examples!\n",
            "Scored 317 examples!\n",
            "Scored 323 examples!\n",
            "Scored 329 examples!\n",
            "Scored 335 examples!\n",
            "Scored 341 examples!\n",
            "Scored 347 examples!\n",
            "Scored 353 examples!\n",
            "Scored 359 examples!\n",
            "Scored 365 examples!\n",
            "Scored 371 examples!\n",
            "Scored 377 examples!\n",
            "Scored 383 examples!\n",
            "Scored 389 examples!\n",
            "Scored 395 examples!\n",
            "Scored 401 examples!\n",
            "Scored 407 examples!\n",
            "Scored 413 examples!\n",
            "Scored 419 examples!\n",
            "Scored 425 examples!\n",
            "Scored 431 examples!\n",
            "Scored 437 examples!\n",
            "Scored 443 examples!\n",
            "Scored 449 examples!\n",
            "Scored 455 examples!\n",
            "Scored 461 examples!\n",
            "Scored 467 examples!\n",
            "Scored 473 examples!\n",
            "Scored 479 examples!\n",
            "Scored 485 examples!\n",
            "Scored 491 examples!\n",
            "Scored 497 examples!\n",
            "Scored 503 examples!\n",
            "Scored 509 examples!\n",
            "Scored 515 examples!\n",
            "Scored 521 examples!\n",
            "Scored 527 examples!\n",
            "Scored 533 examples!\n",
            "Scored 539 examples!\n",
            "Scored 545 examples!\n",
            "Scored 551 examples!\n",
            "Scored 557 examples!\n",
            "Scored 563 examples!\n",
            "Scored 569 examples!\n",
            "Scored 575 examples!\n",
            "Scored 581 examples!\n",
            "Scored 587 examples!\n",
            "Scored 593 examples!\n",
            "Scored 599 examples!\n",
            "Scored 605 examples!\n",
            "Scored 611 examples!\n",
            "Scored 617 examples!\n",
            "Scored 623 examples!\n",
            "Scored 629 examples!\n",
            "Scored 635 examples!\n",
            "Scored 641 examples!\n",
            "Scored 647 examples!\n",
            "Scored 653 examples!\n",
            "Scored 659 examples!\n",
            "Scored 665 examples!\n",
            "Scored 671 examples!\n",
            "Scored 677 examples!\n",
            "Scored 683 examples!\n",
            "Scored 689 examples!\n",
            "Scored 695 examples!\n",
            "Scored 701 examples!\n",
            "Scored 707 examples!\n",
            "Scored 713 examples!\n",
            "Scored 719 examples!\n",
            "Scored 725 examples!\n",
            "Scored 731 examples!\n",
            "Scored 737 examples!\n",
            "Scored 743 examples!\n",
            "Scored 749 examples!\n",
            "Scored 755 examples!\n",
            "Scored 761 examples!\n",
            "Scored 767 examples!\n",
            "Scored 773 examples!\n",
            "Scored 779 examples!\n",
            "Scored 785 examples!\n",
            "Scored 791 examples!\n",
            "Scored 797 examples!\n",
            "Scored 803 examples!\n",
            "Scored 809 examples!\n",
            "Scored 815 examples!\n",
            "Scored 821 examples!\n",
            "Scored 827 examples!\n",
            "Scored 833 examples!\n",
            "Scored 839 examples!\n",
            "Scored 845 examples!\n",
            "Scored 851 examples!\n",
            "Scored 857 examples!\n",
            "Scored 863 examples!\n",
            "Scored 869 examples!\n",
            "Scored 875 examples!\n",
            "Scored 881 examples!\n",
            "Scored 887 examples!\n",
            "Scored 893 examples!\n",
            "Scored 899 examples!\n",
            "Scored 905 examples!\n",
            "Scored 911 examples!\n",
            "Scored 917 examples!\n",
            "Scored 923 examples!\n",
            "Scored 929 examples!\n",
            "Scored 935 examples!\n",
            "Scored 941 examples!\n",
            "Scored 947 examples!\n",
            "Scored 953 examples!\n",
            "Scored 959 examples!\n",
            "Scored 965 examples!\n",
            "Scored 971 examples!\n",
            "Scored 977 examples!\n",
            "Scored 983 examples!\n",
            "Scored 989 examples!\n",
            "Scored 995 examples!\n",
            "Scored 1001 examples!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyGzN4bji5e6",
        "outputId": "6d9b410b-16bb-4f94-b784-8a992264c97d"
      },
      "source": [
        "len(results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "167"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7RZfxf0R5_L"
      },
      "source": [
        "relevant1 = [results[i][:, 1] for i in range(len(results))]\r\n",
        "\r\n",
        "relevant1\r\n",
        "\r\n",
        "relevant1 = []\r\n",
        "for i in range(len(results) - 1):\r\n",
        "    for j in range(5):\r\n",
        "        relevant1.append(float(results[i][:, 1][j]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "42hzo32Xj9AC",
        "outputId": "42ed232e-73fa-431d-a7f7-f4cef9dece21"
      },
      "source": [
        "np.argmax(relevant1)\r\n",
        "\r\n",
        "corpus[181]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'august william derleth february july was an american writer and anthologist though best remembered as the first book publisher of the writings of lovecraft and for his own contributions to the cthulhu mythos and the cosmic horror genre as well as his founding of the publisher arkham house which did much to bring supernatural fiction into print in hardcover in the us that had only been readily available in the uk derleth was leading american regional writer of his day as well as prolific in several other genres including historical fiction poetry detective fiction science fiction and biography guggenheim fellow derleth considered his most serious work to be the ambitious sac prairie saga series of fiction historical fiction poetry and non fiction naturalist works designed to memorialize life in the wisconsin he knew derleth can also be considered pioneering naturalist and conservationist in his writing life the son of william julius derleth and rose louise volk derleth grew up in sauk city wisconsin he was educated in local parochial and public high school derleth wrote his first fiction at age he was interested most in reading and he made three trips to the library week he would save his money to buy books his personal library exceeded later on in life some of his biggest influences were ralph waldo emerson essays walt whitman mencken the american mercury samuel johnson the history of rasselas prince of abissinia alexandre dumas edgar allan poe walter scott and henry david thoreau walden forty rejected stories and three years later according to anthologist jim stephens he sold his first story bat belfry to weird tales magazine derleth wrote throughout his four years at the university of wisconsin where he received in during this time he also served briefly as associate editor of minneapolis based fawcett publications mystic magazine returning to sauk city in the summer of derleth worked in local canning factory and collaborated with childhood friend mark schorer later chairman of the university of california berkeley english department they rented cabin writing gothic and other horror stories and selling them to weird tales magazine derleth won place on the brien roll of honor for five alone published in place of hawks but was first found in pagany magazine as result of his early work on the sac prairie saga derleth was awarded the prestigious guggenheim fellowship his sponsors were helen white nobel prize winning novelist sinclair lewis and poet edgar lee masters of spoon river anthology fame in the mid derleth organized ranger club for young people served as clerk and president of the local school board served as parole officer organized local men club and parent teacher association he also lectured in american regional literature at the university of wisconsin and was contributing editor of outdoors magazine with longtime friend donald wandrei derleth in founded arkham house its initial objective was to publish the works of lovecraft with whom derleth had corresponded since his teenage years at the same time he began teaching course in american regional literature at the university of wisconsin in he became literary editor of the capital times newspaper in madison post he held until his resignation in his hobbies included fencing swimming chess philately and comic strips derleth reportedly used the funding from his guggenheim fellowship to bind his comic book collection most recently valued in the millions of dollars rather than to travel abroad as the award intended derleth true avocation however was hiking the terrain of his native wisconsin lands and observing and recording nature with an expert eye derleth once wrote of his writing methods write very swiftly from to million words yearly very little of it pulp material in he was elected president of the associated fantasy publishers at the th world science fiction convention in toronto he was married april to sandra evelyn winters they divorced six years later derleth retained custody of the couple two children april rose and walden william april earned bachelor of arts degree in english from the university of wisconsin madison in she became majority stockholder president and ceo of arkham house in she remained in that capacity until her death she was known in the community as naturalist and humanitarian april died on march in derleth began editing and publishing magazine called hawk and whippoorwill dedicated to poems of man and nature derleth died of heart attack on july and is buried in st aloysius cemetery in sauk city the bridge over the wisconsin river is named in his honor derleth was roman catholic career derleth wrote more than short stories and more than books during his lifetime the sac prairie saga derleth wrote an expansive series of novels short stories journals poems and other works about sac prairie whose prototype is sauk city derleth intended this series to comprise up to novels telling the projected life story of the region from the th century onwards with analogies to balzac human comedy and proust remembrance of things past this and other early work by derleth made him well known figure among the regional literary figures of his time early pulitzer prize winners hamlin garland and zona gale as well as sinclair lewis the last both an admirer and critic of derleth as edward wagenknecht wrote in cavalcade of the american novel what mr derleth has that is lacking in modern novelists generally is country he belongs he writes of land and people that are bone of his bone and flesh of his flesh in his fictional world there is unity much deeper and more fundamental than anything that can be conferred by an ideology it is clear too that he did not get the best and most fictionally useful part of his background material from research in the library like scott in his border novels he gives rather the impression of having drunk it in with his mother milk jim stephens editor of an august derleth reader argues what derleth accomplished was to gather wisconsin mythos which'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCZmLhQAjh2B",
        "outputId": "497d765f-f03f-4e37-a1ee-0297c15c0abc"
      },
      "source": [
        "float(results[0][:, 1][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.2442232370376587"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_w6l4woRrUc",
        "outputId": "8843367a-4f56-49f4-bc23-63f956df7880"
      },
      "source": [
        "relevant = result[:, 1].numpy()\r\n",
        "np.argmax(relevant)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "136"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKYhIBiISTKt",
        "outputId": "a97ddb7e-521c-440b-e71b-3a62438bcb7d"
      },
      "source": [
        "idx = (-relevant).argsort()[:10]\r\n",
        "\r\n",
        "for i in idx:\r\n",
        "    print(corpus[i])\r\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "alexander graham bell march august was scottish born inventor scientist and engineer who is credited with inventing and patenting the first practical telephone he also co founded the american telephone and telegraph company at in bell father grandfather and brother had all been associated with work on elocution and speech and both his mother and wife were deaf profoundly influencing bell life work his research on hearing and speech further led him to experiment with hearing devices which eventually culminated in bell being awarded the first patent for the telephone on march bell considered his invention an intrusion on his real work as scientist and refused to have telephone in his study many other inventions marked bell later life including groundbreaking work in optical hydrofoils and aeronautics although bell was not one of the founders of the national geographic society he had strong influence on the magazine while serving as the second president from january until beyond his scientific work bell was an advocate of compulsory sterilization and served as chairman or president of several eugenics organizations early life alexander bell was born in edinburgh scotland on march the family home was at south charlotte street and has stone inscription marking it as alexander graham bell birthplace he had two brothers melville james bell and edward charles bell both of whom would die of tuberculosis his father was professor alexander melville bell phonetician and his mother was eliza grace bell née symonds born as just alexander bell at age he made plea to his father to have middle name like his two brothers for his th birthday his father acquiesced and allowed him to adopt the name graham chosen out of respect for alexander graham canadian being treated by his father who had become family friend to close relatives and friends he remained aleck first invention as child young bell displayed curiosity about his world he gathered botanical specimens and ran experiments at an early age his best friend was ben herdman neighbour whose family operated flour mill at the age of bell built homemade device that combined rotating paddles with sets of nail brushes creating simple dehusking machine that was put into operation at the mill and used steadily for number of years in return ben father john herdman gave both boys the run of small workshop in which to invent from his early years bell showed sensitive nature and talent for art poetry and music that was encouraged by his mother with no formal training he mastered the piano and became the family pianist despite being normally quiet and introspective he revelled in mimicry and voice tricks akin to ventriloquism that continually entertained family guests during their occasional visits bell was also deeply affected by his mother gradual deafness she began to lose her hearing when he was and learned manual finger language so he could sit at her side and tap out silently the conversations swirling around the family parlour he also developed technique of speaking in clear modulated tones directly into his mother forehead wherein she would hear him with reasonable clarity bell preoccupation with his mother deafness led him to study acoustics his family was long associated with the teaching of elocution his grandfather alexander bell in london his uncle in dublin and his father in edinburgh were all elocutionists his father published variety of works on the subject several of which are still well known especially his the standard elocutionist which appeared in edinburgh in the standard elocutionist appeared in british editions and sold over quarter of million copies in the united states alone in this treatise his father explains his methods of how to instruct deaf mutes as they were then known to articulate words and read other people lip movements to decipher meaning bell father taught him and his brothers not only to write visible speech but to identify any symbol and its accompanying sound bell became so proficient that he became part of his father public demonstrations and astounded audiences with his abilities he could decipher visible speech representing virtually every language including latin scottish gaelic and even sanskrit accurately reciting written tracts without any prior knowledge of their pronunciation education as young child bell like his brothers received his early schooling at home from his father at an early age he was enrolled at the royal high school edinburgh scotland which he left at the age of having completed only the first four forms his school record was undistinguished marked by absenteeism and lacklustre grades his main interest remained in the sciences especially biology while he treated other school subjects with indifference to the dismay of his father upon leaving school bell travelled to london to live with his grandfather alexander bell on harrington square during the year he spent with his grandfather love of learning was born with long hours spent in serious discussion and study the elder bell took great efforts to have his young pupil learn to speak clearly and with conviction the attributes that his pupil would need to become teacher himself at the age of bell secured position as pupil teacher of elocution and music in weston house academy at elgin moray scotland although he was enrolled as student in latin and greek he instructed classes himself in return for board and per session the following year he attended the university of edinburgh joining his older brother melville who had enrolled there the previous year in not long before he departed for canada with his family bell completed his matriculation exams and was accepted for admission to university college london first experiments with sound his father encouraged bell interest in speech and in took his sons to see unique automaton developed by sir charles wheatstone based on the earlier work of baron wolfgang von kempelen the rudimentary mechanical man simulated human voice bell was fascinated by the machine and after he obtained copy of von kempelen book published in german and had laboriously translated it\n",
            "\n",
            "aba may refer to geographic toponyms aba abia commercial city in eastern nigeria aba tibetan and qiang autonomous prefecture sichuan china aba county aba prefecture sichuan china aba sichuan main town in aba county aba democratic republic of the congo aba hungary town in fejér county hungary abeh ye now village in semnan province iran aba okayama village in japan aba island in the white nile river sudan aba river nigeria river in nigeria aba russia river in kemerovo oblast russia itu aba island in the south china sea alternate transliteration of upu historic region surrounding damascus people aba indian tribe clan of the indians aba family clan in hungary aba people clan of the shor in russia aba andam ghanaian physicist aba bayefsky canadian artist and teacher aba cercato italian television presenter mar abba or aba metropolitan bishop and saint of the assyrian church of the east samuel aba of hungary th century leader vilmos aba novák hungarian painter saint aba of kaskhar th century martyr johnny aba born papua new guinean boxer of the and animals the aba gymnarchus niloticus species of fish native to africa aba roundleaf bat west africa bat media aba film sri lanka film aba daba honeymoon song other uses aba short form of abaya middle eastern robe aba women riots of in nigeria aba dune robe in the fictional dune universe aba mythology thracian naiad abscisic acid plant hormone applied behavior analysis anglican province of aba nigeria roman catholic diocese of aba nigeria aba problem synchronization issue in multithreaded computing see also abas disambiguation abba disambiguation ab semitic\n",
            "\n",
            "\n",
            "abyssinia is historical name for the ethiopian empire nation that comprised the northern half of present day ethiopia abyssinia may also refer to places ethiopia the modern nation that continues to be known by the name abyssinia abyssinia lines neighbourhood of jamshed town in karachi sindh pakistan apostolic vicariate of abyssinia the former eastern catholic missionary arts and media abyssinia theatrical show by bert williams abyssinia musical show first staged in abyssinia song by the patti smith group on radio ethiopia abyssinia henry an episode of the television series vessels ss abyssinia an canadian pacific steamship hms abyssinia british armoured ship other uses abyssinia battle honour abyssinia creek the pilbara western australia see also abyssinian disambiguation habash disambiguation habishi disambiguation history of ethiopia\n",
            "\n",
            "\n",
            "asia minor is an alternative name for anatolia the westernmost protrusion of asia comprising the majority of the republic of turkey asia minor may also refer to asia minor album an album by jamaican born jazz trumpeter dizzy reece asia minor instrumental instrumental recording by jimmy wisner operating under the name kokomo see also asia major disambiguation\n",
            "\n",
            "\n",
            "aw aw aw or aw may refer to people aw surname cantonese surname poet anonymous th century poet wrestler ring name of brian bary jossie musician an american singer songwriter formerly known as allison weiss alan walker music producer born uses the initials and logo aw weiler new york times film critic whose early reviews were signed with his initials places ahrweiler district germany vehicle registration code aruba iso letter country code aw companies restaurants root beer addison wesley publishers africa world airlines iata code prefix for helicopters made by agustawestland aw allied waste industries inc stock symbol on nyse armstrong whitworth british manufacturing company in the early th century media and entertainment active worlds virtual reality platform another world tv series an american soap opera aviation week magazine accel world japanese light novel series science and technology aw or water activity the relative availability of water in substance airwatt unit of the effectiveness of vacuum cleaners aw or attowatt an si unit of power aw the internet top level domain country code for aruba aw categorization for tropical savanna climate in the köppen classification system aw in german email subject line equivalent to re other uses aw us navy hull classification symbol for distilling ship agencja wywiadu the polish foreign intelligence service ahnapee and western railway arctic warfare sniper rifle manufactured by the british company accuracy international aviation warfare systems operator rating in the united states navy aw digraph in latin script see also av\n",
            "\n",
            "\n",
            "the economy of american samoa is traditional polynesian economy in which more than of the land is communally owned economic activity is strongly linked to the united states with which american samoa conducts the great bulk of its foreign trade tuna fishing and processing plants are the backbone of the private sector with canned tuna being the primary export transfers from the federal government add substantially to american samoa economic well being attempts by the government to develop larger and broader economy are restrained by samoa remote location its limited transportation and its devastating hurricanes starkist tuna cannery tuna canning represents major export industry in the territory statistics employment in the canning industry in american samoa employment in the industry fell following the closure of chicken of the sea cannery gdp purchasing power parity million est country comparison to the world gdp official exchange rate million gdp real growth rate country comparison to the world gdp per capita purchasing power parity country comparison to the world gdp composition by sector agriculture na industry na services na labor force country comparison to the world labor force by occupation government tuna canneries other unemployment rate country comparison to the world population below poverty line na est household income or consumption by percentage share lowest na highest na inflation rate consumer prices na est budget revenues million in local revenue and in us grants expenditures million fy agriculture products bananas coconuts vegetables taro breadfruit yams copra pineapples papayas dairy products livestock industries tuna canneries largely dependent on foreign fishing vessels handicrafts industrial production growth rate na electricity production gwh country comparison to the world electricity production by source fossil fuel hydro nuclear other electricity consumption gwh country comparison to the world electricity exports kwh electricity imports kwh oil production est country comparison to the world oil consumption m³ country comparison to the world oil exports country comparison to the world oil imports country comparison to the world natural gas production cu country comparison to the world natural gas consumption cu country comparison to the world natural gas exports cu country comparison to the world natural gas imports cu country comparison to the world natural gas proved reserves cu country comparison to the world exports million country comparison to the world exports commodities canned tuna exports partners indonesia australia japan samoa imports million country comparison to the world imports commodities materials for canneries food petroleum products machinery and parts imports partners australia new zealand south korea mauritius debt external na est economic aid recipient na note important financial support from the us more than million in currency us dollar usd currency code usd exchange rates us dollar is used fiscal year october september references external links http www classbrain com art_cr publish shtml\n",
            "\n",
            "\n",
            "the arizona diamondbacks often shortened as the backs are an american professional baseball team based in phoenix arizona the diamondbacks compete in major league baseball mlb as member club of the national league nl west division the team plays its home games at chase field formerly known as bank one ballpark throughout its history arizona has won one world series championship defeating the new york yankees in becoming the fastest expansion team in major league history to win championship which it did in only the fourth season since the franchise inception franchise history on march phoenix was awarded an expansion franchise to begin play for the season million franchise fee was paid to major league baseball and on january the diamondbacks were officially voted into the national league the diamondbacks first major league game was played against the colorado rockies on march at bank one ballpark the ballpark was renamed chase field in as result of bank one corporation merger with jpmorgan chase co since their debut the diamondbacks have won five nl west division titles one nl pennant one wild card game and the world series from to the diamondbacks have an overall record of logos the diamondbacks original colors were purple black teal and copper their first logo was an italicized block letter with diamond pattern and the crossbar represented by snake tongue prior to their inaugural season they released their baseball caps the home cap had cream color crown with purple visor and button the road cap was black and had turquoise visor and button their alternate cap had turquoise crown with purple visor and button depending on the cap the logo on the front of the cap had different color variations in the diamondbacks second season they introduced new logo which was copper color snake in the shape of letter it was used on solid black cap which in the beginning was worn as road cap the franchise unveiled new uniforms and colors of sedona red sonoran sand and black on november the red shade is named for the sandstone canyon at red rock state park near sedona while the beige sand shade is named for the sonoran desert sleeve patch was added featuring lowercase and configured to look like snake head the team also kept the logo but was slightly altered and put on an all red cap to be used as their game cap they also kept the logo with the new colors applied to it with solid black cap used as the alternate cap similar color scheme is currently used by the arizona coyotes of the national hockey league prior to the season the diamondbacks reincorporated teal into its color scheme while keeping sedona red sonoran sand and black they also unveiled eight different uniform combinations including two separate home white and away grey uniforms one major difference between the two sets is that the non teal uniforms feature snakeskin pattern on the shoulders while the teal trimmed uniforms include charcoal grey snakeskin pattern on the back arizona also kept the throwback pinstriped sleeveless uniforms from their championship season for use during thursday home games starting with the season the diamondbacks made slight redesigns to their current uniforms the snakeskin patterns were removed while the teal trimmed grey uniforms were retired the team also reverted to standard grey uniform after wearing darker shade on the previous set two home white uniforms remain in use the primary sedona red and the alternate teal they would also wear two black uniforms one with the primary logo on the left chest and the other with los backs trimmed in teal three cap designs were also unveiled the primary cap the teal trimmed snake cap paired exclusively on the teal alternates and the sand trimmed snake cap paired exclusively on the sedona red alternates the nike swoosh logo is also placed on the right chest near the shoulder regular season home attendance home attendance year total attendance game average league rank nd th th th nd th th th th th th th th th th th th th th th th th radio and television the primary television play by play voice for the team first nine seasons of play was thom brennaman who also broadcast baseball and college football games nationally for fox television brennaman was the tv announcer for the chicago cubs and cincinnati reds along with his father marty brennaman before being hired by diamondbacks founder jerry colangelo in two years before the team would begin play in october brennaman left the diamondbacks to call games with his father for the reds beginning in signing four year deal his fox duties remained unchanged the english language flagship radio station is ktar greg schulte is the regular radio play by play voice year veteran of sports radio in the phoenix market also well known for his previous work on phoenix suns arizona cardinals and arizona state university asu broadcasts jeff munn is backup radio play by play announcer he served as the regular public address announcer at chase field in the early days of the franchise he is well known to many phoenix area sports fans having also served as the public address announcer for the suns at america west arena now talking stick resort arena in the he is also the play by play radio voice for asu women basketball on november the team announced that the tv voice of the milwaukee brewers since daron sutton would be hired as the diamondbacks primary tv play by play voice sutton was signed to five year contract with team option for three more years sutton is considered one of the best of the younger generation of baseball broadcasters his signature chants include let get some runs when the backs trail in late innings sutton father is hall of fame pitcher and current atlanta braves broadcaster don sutton former diamondbacks and chicago cubs first baseman mark grace and former major league knuckleball pitcher tom candiotti were\n",
            "\n",
            "satellite composite image of antarctica the antarctic treaty and related agreements collectively known as the antarctic treaty system ats regulate international relations with respect to antarctica earth only continent without native human population for the purposes of the treaty system antarctica is defined as all of the land and ice shelves south of latitude the treaty entered into force in and currently has parties the treaty sets aside antarctica as scientific preserve establishes freedom of scientific investigation and bans military activity on the continent the treaty was the first arms control agreement established during the cold war since september the antarctic treaty secretariat headquarters has been located in buenos aires argentina the main treaty was opened for signature on december and officially entered into force on june the original signatories were the countries active in antarctica during the international geophysical year igy of the twelve countries that had significant interests in antarctica at the time were argentina australia belgium chile france japan new zealand norway south africa the soviet union the united kingdom and the united states these countries had established over antarctic stations for the igy the treaty was diplomatic expression of the operational and scientific co operation that had been achieved on the ice history international conflicts various international conflicts motivated the creation of an agreement for the antarctic after the second world war the considered establishing claim in antarctica from august and until the beginning of operation highjump was carried out the largest military expeditionary force that the united states has sent to antarctica to the present consisting of ships men and numerous aerial devices its goals were to train military personnel and test material in conditions of extreme cold for an eventual war in the antarctic some incidents had occurred during world war ii and new one occurred in hope bay on february when the argentine military fired warning shots at group of britons the response of the united kingdom was to send warship that landed marines on february at the scene this occurred however after argentina chile and the united kingdom signed tripartite naval declaration committing not to send warships south of the th south parallel which was renewed annually until when it was deemed unnecessary when the treaty entered into force this tripartite declaration was signed after the tension generated when argentina sent to antarctica in february fleet of warships on january argentina reopened the lieutenant lasala refuge on deception island leaving sergeant and corporal in the argentine navy on february in the incident on deception island royal marines landed from the british frigate hms snipe armed with sten machine guns rifles and tear gas capturing the two argentine sailors the argentine refuge and nearby uninhabited chilean shelter were destroyed and the argentine sailors were delivered to ship from that country on february in the south georgias islands british detachment remained three months on the island while the frigate patrolled its waters until april on may the united kingdom filed two lawsuits against argentina and chile respectively before the international court of justice to declare the invalidity of the claims of the sovereignty of the two countries over antarctic and sub antarctic areas on july the chilean government rejected the jurisdiction of the court in that case and on august the argentine government also did so so on march the claims were filed previous agreements on september the american quadrant of antarctica between and was included as part of the security zone of the inter american treaty of reciprocal assistance committing its members to defend it in case of external aggression in august the united states proposed that antarctica be under the guardianship of the united nations as trust administered by argentina australia chile france united states united kingdom and new zealand still the idea was rejected by argentina australia chile france and norway before the rejection on august the united states proposed to the claimants some form of of antarctica with the support of the united kingdom chile responded by presenting plan to suspend any antarctic claim for to years while negotiating final solution which did not prosper the interest of the united states to keep the soviet union away from antarctica was frustrated when in this country informed the claimants that it would not accept any antarctic agreement in which it was not represented the fear that the ussr would react by doing territorial claim transferring the cold war to antarctica led the united states to do none in and india tried unsuccessfully to bring the antarctic issue to the united nations general assembly international geophysical year in the international council of scientific unions icsu discussed the possibility of holding third international polar year at the suggestion of the world meteorological organization the idea of the international polar year was extended to the entire planet thus creating the international geophysical year that took place between july and december in this event countries participated at the icsu meeting in stockholm from september to the creation of special committee for antarctic research scar was approved inviting the twelve countries conducting antarctic investigations to send delegates to integrate the committee with the purpose of exchanging scientific information among its members regarding antarctica the scar was later renamed to the scientific committee for research in antarctica both argentina and chile expressed that researching during the international geophysical year would not give any territorial rights to the participants and that the facilities that were erected during that year should then be dismantled at the end of it after the united states proposed to extend the antarctic investigations for another year in february the soviet union reported that it would maintain its scientific bases until the studies that were carried out were completed negotiation of the treaty scientific bases increased in international tension concerning antarctica and the danger of the cold war spreading to that continent caused the president of the united states dwight eisenhower to convene an antarctic conference to the twelve countries active in antarctica during\n",
            "\n",
            "an animal is multicellular eukaryotic organism of the kingdom animalia or metazoa animal or animals or the animal may also refer to people the animal nickname set index of people nicknamed the animal or animal professional wrestlers road warrior animal commonly shortened to animal the best known ring persona of joe laurinaitis animal hamaguchi ring name of japanese retired wrestler heigo hamaguchi born george steele american retired professional wrestler author and actor known as the animal dave bautista born american retired professional wrestler whose nickname is the animal books and publications animal book full title animal the definitive visual guide to the world wildlife non fiction book by david burnie and several co authors animal novel by wan foye animal journal full title animal an international journal of animal bioscience british academic journal animals novel novel by emma jane unsworth film and television film animal film french film animal starring jean paul belmondo and raquel welch animal film argentine comedy film by sergio bizzio with carlos roffé animal film us direct to video action drama film starring ving rhames and terrance howard animal film us horror film starring keke palmer animals film stand up show written and performed by ricky gervais animals film spanish film animals film uk drama film written by and starring david dastmalchian animals film german film animals film australian film the animal us comedy film featuring rob schneider the animals film filipino coming of age film by gino santos television animals tv series american animated television series animals south korean tv series south korean tv series animals the goodies television series episode animals an episode of men behaving badly animals an episode of off the air animals an episode of the vicar of dibley animal audio drama an audio drama based on the television series doctor who characters animal muppet character from the television series the muppet show animal character in the television series takeshi castle animal played by ken hudson campbell character on the tv sitcom herman head music the animals british rock band an argentinian heavy metal band animal nick culmer lead singer of the anti nowhere league albums animal animosity album animal kesha album animal motor ace album animals pink floyd album animals this town needs guns album animals ep by ryan starx the animals american album by the animals the animals british album by the animals animal album by autokratz animal album by the bar kays animal album by berlin animal album by far east movement animal album by margot the nuclear so and so songs animal álvaro soler song animal conor maynard song animal def leppard song animal jebediah song animal juvenile song animal kesha song animal miike snow song animal neon trees song animal pearl jam song animal song animal troye sivan song animal song animals kevin ayers song animal fuck like beast by animals maroon song animals martin garrix song animals muse song animals nickelback song the animal disturbed song animal by against me from new wave animal by ani difranco from educated guess animal by aurora from different kind of human step animal by black light burns from cruel melody animal by ellie goulding from lights animal by karen and the kids from where the wild things are animal by kat deluna from lives animal by mindless self indulgence from if animal by mudmen from overrated animal by subhumans from demolition war animal by sunhouse from crazy on the weekend animal by the kinks from to the bone animal by toto from past to present animals by cocorosie from the adventures of ghosthorse and stillborn animals by coldplay as one of the sides for clocks animals by dead poetic from vices animals by talking heads from fear of music animals by the end from elementary animals by todrick hall featuring matt bloyd from forbidden the animal by steve vai from passion and warfare other animal computer worm an early self replicating computer program animal image processing an interactive software environment for image processing animal clothing sportswear retailer and brand based in the united kingdom animals israeli organization an animal rights group based in israel see also animals animals animals an american educational television series animalia disambiguation animalism disambiguation\n",
            "\n",
            "\n",
            "apollo was the tenth crewed mission in the united states apollo space program the fifth and penultimate to land on the moon and the second to land in the lunar highlands the second of apollo missions it was crewed by commander john young lunar module pilot charles duke and command module pilot ken mattingly launched from the kennedy space center in florida at pm est on april the mission lasted days hour and minutes and concluded at est on april after flying the apollo lunar module to the moon surface on april young and duke spent hours just under three days on the lunar surface during which they conducted three extra vehicular activities or moonwalks totaling hours and minutes the pair drove the lunar roving vehicle lrv the second produced and used on the moon for on the surface young and duke collected of lunar samples for return to earth while command module pilot ken mattingly orbited in the command and service module csm above to perform observations mattingly staying with the command module spent hours and revolutions in lunar orbit after young and duke rejoined mattingly in lunar orbit the crew released subsatellite from the service module sm during the return trip to earth mattingly performed one hour spacewalk to retrieve several film cassettes from the exterior of the service module apollo landing spot in the highlands was chosen to allow the astronauts to gather geologically older lunar material than the samples obtained in three of the first four moon landings which were in or near lunar maria apollo landed in the fra mauro highlands samples from the descartes formation and the cayley formation disproved hypothesis that the formations were volcanic in origin crew mattingly had originally been assigned to the prime crew of apollo but was exposed to rubella through duke at that time on the back up crew for apollo who had caught it from one of his children he never contracted the illness but was nevertheless removed from the crew and replaced by his backup jack swigert three days before the launch young captain in the united states navy had flown on three spaceflights prior to apollo gemini gemini and apollo which orbited the moon one of astronauts selected by nasa in april duke had never flown in space before apollo he served on the support crew of apollo and was capsule communicator capcom for apollo backup crew although not officially announced the original backup crew consisted of fred haise cdr william pogue cmp and gerald carr lmp who were targeted for the prime crew assignment on apollo however after the cancellations of apollos and were finalized in september this crew would not rotate to lunar mission as planned subsequently roosa and mitchell were recycled to serve as members of the backup crew after returning from apollo while pogue and carr were reassigned to the skylab program where they flew on skylab support crew anthony england karl henize henry hartsfield jr robert overmyer donald peterson mission insignia the insignia of apollo is dominated by rendering of an american eagle and red white and blue shield representing the people of the united states over gray background representing the lunar surface overlaying the shield is gold nasa vector orbiting the moon on its gold outlined blue border there are stars representing the mission number and the names of the crew members young mattingly duke the insignia was designed from ideas originally submitted by the crew of the mission silver robbins medallion planning and training landing site selection apollo was the second of the apollo type missions featuring the use of the lunar roving vehicle increased scientific capability and lunar surface stays of three days as apollo was the penultimate mission in the apollo program and there was no new hardware or procedures to test on the lunar surface the last two missions the other being apollo presented opportunities for astronauts to clear up some uncertainties in understanding the moon properties although previous apollo expeditions including apollo and apollo obtained samples of pre mare lunar material before lava began to upwell from the moon interior and flood the low areas and basins none had actually visited the lunar highlands apollo had visited and sampled ridge of material ejected by the impact that created the mare imbrium impact basin likewise apollo had also sampled material in the region of imbrium visiting the basin edge there remained the possibility because the apollo and apollo landing sites were closely associated with the imbrium basin that different geologic processes were prevalent in areas of the lunar highlands far from mare imbrium several members of the scientific community remarked that the central lunar highlands resembled regions on earth that were created by volcanic processes and hypothesized the same might be true on the moon they hoped scientific output from the apollo mission would provide an answer location of the apollo landing site oblique closeup of the proposed apollo landing site as photographed by apollo from lunar orbit north ray crater is at left and south ray crater is at right with bright rays two locations on the moon were given primary consideration for exploration by the apollo expedition the descartes highlands region west of mare nectaris and the crater alphonsus at descartes the cayley and descartes formations were the primary areas of interest in that scientists suspected based on telescopic and orbital imagery that the terrain found there was formed by magma more viscous than what had formed the lunar maria the cayley formation age was approximated to be about the same as mare imbrium based on the local frequency of impact craters the considerable distance between the descartes site and previous apollo landing sites would be beneficial for the network of geophysical instruments portions of which were deployed on each apollo expedition beginning with apollo at the alphonsus three scientific objectives were determined to be of primary interest and paramount importance the possibility of old pre imbrium impact material from within the crater\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "TI6sGLwUU9iG",
        "outputId": "3ddadbb4-545d-428f-d760-16b9618f2c19"
      },
      "source": [
        "s = \"hello this is a string\"\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'h'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfsdNocGQPB3",
        "outputId": "4d5da3b6-c3b1-4b31-d388-a56e70874bb4"
      },
      "source": [
        "# 0 irrelevant\r\n",
        "# 1 relevant\r\n",
        "tf.sigmoid(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1000, 2), dtype=float32, numpy=\n",
              "array([[0.5927905 , 0.50612324],\n",
              "       [0.5900165 , 0.5075011 ],\n",
              "       [0.5889913 , 0.5086619 ],\n",
              "       ...,\n",
              "       [0.5847367 , 0.51289463],\n",
              "       [0.5910369 , 0.51000524],\n",
              "       [0.59150994, 0.51786286]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ti5rYH3zZzC1"
      },
      "source": [
        "top_article = tf.argmax(result).numpy()[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "id": "1D-bte8lVM0T",
        "outputId": "8da36bfa-2691-445b-b779-7735375f3eca"
      },
      "source": [
        "corpus[top_article]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'the artistic license is software license used for certain free and open source software packages most notably the standard implementation of the perl programming language and most cpan modules which are dual licensed under the artistic license and the gnu general public license gpl history artistic license the original artistic license was written by larry wall the name of the license is reference to the concept of artistic license whether or not the original artistic license is free software license is largely unsettled the free software foundation explicitly called the original artistic license non free license criticizing it as being too vague some passages are too clever for their own good and their meaning is not clear the fsf recommended that the license not be used on its own but approved the common al gpl dual licensing approach for perl projects in response to this bradley kuhn who later worked for the free software foundation made minimal redraft to clarify the ambiguous passages this was released as the clarified artistic license and was approved by the fsf it is used by the paros proxy the javafbp toolkit and ncftp the terms of the artistic license were at issue in jacobsen katzer in the initial ruling by the united states district court for the northern district of california declared that foss like licenses could only be enforced through contract law rather than through copyright law in contexts where contract damages would be difficult to establish on appeal federal appellate court determined that the terms of the artistic license are enforceable copyright conditions the case was remanded to the district court which did not apply the superior court criteria on the grounds that in the interim the governing supreme court precedent applicable to the case had changed however this left undisturbed the finding that free and open source license nonetheless has economic value jacobsen ultimately prevailed in and the case established new standard making terms and conditions under artistic license enforceable through copyright statutes and relevant precedents artistic license in response to the request for comments rfc process for improving the licensing position for perl kuhn draft was extensively rewritten by roberta cairney and allison randal for readability and legal clarity with input from the perl community this resulted in the artistic license which has been approved as both free software and open source license the artistic license is also notable for its excellent license compatibility with other foss licenses due to relicensing clause property other licenses like the gpl are missing it has been adopted by some of the perl implementations and has been used by the parrot virtual machine since version it is also used by the sneese emulator which was formerly licensed under the clarified artistic license the osi recommends that all developers and projects licensing their products with the artistic license adopt artistic license see also software using the artistic license category references external links version the artistic licensethe original artistic license the one which is still used by perl and cpan they use disjunction of the artistic license and the gnu gpl for perl and above the clarified artistic license version the artistic license it used by parrot revision rfc process prominent uses duskthe first online novel and blog written under artistic license releases videos under artistic license is about choice of the artistic license for videos from one of their albums\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKkbrPFxSpqh",
        "outputId": "ac3de967-1c5f-478e-a506-18df280ad001"
      },
      "source": [
        "print(tf_corpus.shape.as_list())\r\n",
        "print(tf_query.shape.as_list())\r\n",
        "\r\n",
        "# Great!"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1000, None]\n",
            "[1000, None]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_F5qYoiUqSC"
      },
      "source": [
        "input_word_ids = tf.concat([tf_query, tf_corpus], axis = - 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nr7aEmp-UxjP"
      },
      "source": [
        "input_mask = tf.ones_like(input_word_ids).to_tensor()\r\n",
        "type_cls = tf.zeros_like(%colors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9MAqUhJJcv0",
        "outputId": "73eae3d8-48de-4afa-a4a7-a6e615bf30db"
      },
      "source": [
        "# Build the model\r\n",
        "import json\r\n",
        "\r\n",
        "bert_config_file = os.path.join(gs_folder_bert, \"bert_config.json\")\r\n",
        "config_dict = json.loads(tf.io.gfile.GFile(bert_config_file).read())\r\n",
        "\r\n",
        "bert_config = bert.configs.BertConfig.from_dict(config_dict)\r\n",
        "\r\n",
        "config_dict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_probs_dropout_prob': 0.1,\n",
              " 'hidden_act': 'gelu',\n",
              " 'hidden_dropout_prob': 0.1,\n",
              " 'hidden_size': 768,\n",
              " 'initializer_range': 0.02,\n",
              " 'intermediate_size': 3072,\n",
              " 'max_position_embeddings': 512,\n",
              " 'num_attention_heads': 12,\n",
              " 'num_hidden_layers': 12,\n",
              " 'type_vocab_size': 2,\n",
              " 'vocab_size': 30522}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73FCix8DMJ8O"
      },
      "source": [
        "bert_classifier, bert_encoder = bert.bert_models.classifier_model(\r\n",
        "    bert_config, num_labels = 2\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Toik0mzDXT34"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}