audio signal processing is subfield of signal processing that is concerned with the electronic manipulation of audio signals audio signals are electronic representations of sound waves longitudinal waves which travel through air consisting of compressions and rarefactions the energy contained in audio signals is typically measured in decibels as audio signals may be represented in either digital or analog format processing may occur in either domain analog processors operate directly on the electrical signal while digital processors operate mathematically on its digital representation history the motivation for audio signal processing began at the beginning of the th century with inventions like the telephone phonograph and radio that allowed for the transmission and storage of audio signals audio processing was necessary for early radio broadcasting as there were many problems with studio to transmitter links the theory of signal processing and its application to audio was largely developed at bell labs in the mid th century claude shannon and harry nyquist early work on communication theory sampling theory and pulse code modulation pcm laid the foundations for the field in max mathews became the first person to synthesize audio from computer giving birth to computer music major developments in digital audio coding and audio data compression include differential pulse code modulation dpcm by chapin cutler at bell labs in linear predictive coding lpc by fumitada itakura nagoya university and shuzo saito nippon telegraph and telephone in adaptive dpcm adpcm by cummiskey nikil jayant and james flanagan at bell labs in discrete cosine transform dct coding by nasir ahmed natarajan and rao in and modified discrete cosine transform mdct coding by princen johnson and bradley at the university of surrey in lpc is the basis for perceptual coding and is widely used in speech coding while mdct coding is widely used in modern audio coding formats such as mp and advanced audio coding aac analog signals an analog audio signal is continuous signal represented by an electrical voltage or current that is analogous to the sound waves in the air analog signal processing then involves physically altering the continuous signal by changing the voltage or current or charge via electrical circuits historically before the advent of widespread digital technology analog was the only method by which to manipulate signal since that time as computers and software have become more capable and affordable digital signal processing has become the method of choice however in music applications analog technology is often still desirable as it often produces nonlinear responses that are difficult to replicate with digital filters digital signals digital representation expresses the audio waveform as sequence of symbols usually binary numbers this permits signal processing using digital circuits such as digital signal processors microprocessors and general purpose computers most modern audio systems use digital approach as the techniques of digital signal processing are much more powerful and efficient than analog domain signal processing application areas processing methods and application areas include storage data compression music information retrieval speech processing localization acoustic detection transmission noise cancellation acoustic fingerprinting sound recognition synthesis and enhancement equalization filtering level compression echo and reverb removal or addition etc audio broadcasting audio signal processing is used when broadcasting audio signals in order to enhance their fidelity or optimize for bandwidth or latency in this domain the most important audio processing takes place just before the transmitter the audio processor here must prevent or minimize overmodulation compensate for non linear transmitters potential issue with medium wave and shortwave broadcasting and adjust overall loudness to desired level active noise control active noise control is technique designed to reduce unwanted sound by creating signal that is identical to the unwanted noise but with the opposite polarity the two signals cancel out due to destructive interference audio synthesis audio synthesis is the electronic generation of audio signals musical instrument that accomplishes this is called synthesizer synthesizers can either imitate sounds or generate new ones audio synthesis is also used to generate human speech using speech synthesis audio effects audio effects are systems designed to alter how an audio signal sounds unprocessed audio is metaphorically referred to as dry while processed audio is referred to as wet delay or echo to simulate the effect of reverberation in large hall or cavern one or several delayed signals are added to the original signal to be perceived as echo the delay has to be of order milliseconds or above short of actually playing sound in the desired environment the effect of echo can be implemented using either digital or analog methods analog echo effects are implemented using tape delays or bucket brigade devices when large numbers of delayed signals are mixed reverberation effect is produced the resulting sound has the effect of being presented in large room flanger to create an unusual sound delayed signal is added to the original signal with continuously variable delay usually smaller than ms this effect is now done electronically using dsp but originally the effect was created by playing the same recording on two synchronized tape players and then mixing the signals together as long as the machines were synchronized the mix would sound more or less normal but if the operator placed his finger on the flange of one of the players hence flanger that machine would slow down and its signal would fall out of phase with its partner producing phasing comb filter effect once the operator took his finger off the player would speed up until it was back in phase with the master and as this happened the phasing effect would appear to slide up the frequency spectrum this phasing up and down the register can be performed rhythmically phaser another way of creating an unusual sound the signal is split portion is filtered with variable all pass filter to produce phase shift and then the unfiltered and filtered signals are mixed to produce comb filter the phaser effect was originally simpler implementation of the flanger effect since delays were difficult to implement with analog equipment